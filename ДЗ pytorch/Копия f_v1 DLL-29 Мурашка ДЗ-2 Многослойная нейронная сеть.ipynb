{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVlcKfulsvLPM7s8eyZyqe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Домашнее задание по теме «Многослойная нейронная сеть»<br>\n","Цель задания: <br>\n","научиться на простейшем уровне подбирать архитектуру полносвязной нейронной сети для получения качества решения задачи не ниже заданного.\n","<br><br>\n","Задание<br>\n","Постройте модель на основе полносвязных слоёв для классификации Fashion MNIST из библиотеки torchvision (datasets).<br>\n","Получите качество на тестовой выборке не ниже 88%\n","<br><br>\n","Инструкция по выполнению задания\n","<br><br>\n","Скачайте тренировочную и тестовою часть датасета Fashion MNIST<br>\n","Постройте модель, выбрав стартовую архитектуру<br>\n","Обучите модель и сверьте качество на тестовой части с заданным порогом<br>\n","Изменяйте архитектуру модели пока качество на тестовой части не будет выше порога. <br>Вариации архитектуры можно реализовать через изменение количества слоёв, количества нейронов в слоях и использование регуляризации.<br> Можно использовать различные оптимизаторы.<br>\n","<br>\n","Критерии оценки<br>\n","Задание считается выполненным, если:<br><br>\n","\n","модель обучается<br>\n","модель показала качество на тесте более 88%<br>"],"metadata":{"id":"x32OG7Op9ba7"}},{"cell_type":"markdown","source":["первая строка  \n","вторая строка  \n","два пробела и ентер  \n"],"metadata":{"id":"rKu_xHisAMr8"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","import time\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","\n","import torchvision as tv\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"bgos6fNw9cBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE=256"],"metadata":{"id":"thl39QLl-mmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = tv.datasets.FashionMNIST(root = '.', train = True, download=True, transform=tv.transforms.ToTensor())\n","test_dataset = tv.datasets.FashionMNIST(root = '.', train = False, download=True, transform=tv.transforms.ToTensor())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGgJ_6qRCoZe","executionInfo":{"status":"ok","timestamp":1701131292129,"user_tz":-180,"elapsed":6777,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"04332541-90c9-4189-ae79-da0db669a2ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 18226882.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 310604.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 5531922.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 4267248.42it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"MCUwug_FD3qU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0][0].shape"],"metadata":{"id":"-ZivcBZKAkut","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701131358571,"user_tz":-180,"elapsed":261,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"33335f0d-99ee-49ee-ce4e-8c571279d1bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["28*28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wu3T_8UyVVct","executionInfo":{"status":"ok","timestamp":1701131428487,"user_tz":-180,"elapsed":254,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"08d68e09-c799-458b-ad91-c65809dab031"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["784"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Flatten(), # вытягиваем в вектор\n","    torch.nn.Linear(784, 256), # полносвязный слой с входом 28х28=784 и выходом 256\n","    torch.nn.ReLU(), # функция активации\n","    torch.nn.Linear(256, 10) # полносвязный слой с входом 256 и выходом 10 - каждый нейрон отвечает за свою цифру/класс\n",")"],"metadata":{"id":"RspV8EfxAk7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"1ssTwrEhAlE3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701132990116,"user_tz":-180,"elapsed":343,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"f73bf755-f091-458f-83f8-de4f16d782d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Flatten(start_dim=1, end_dim=-1)\n","  (1): Linear(in_features=784, out_features=256, bias=True)\n","  (2): ReLU()\n","  (3): Linear(in_features=256, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","trainer = torch.optim.SGD(model.parameters(), lr=.01) # оптимайзер функции потерь (передали туда параметры и шаг обучения) - схокастический градиентный спуск\n","num_epochs = 10 # кол-во эпох"],"metadata":{"id":"Sibz_9wLAlPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # обучаем модель\n","def train_model():\n","    for ep in range(num_epochs):\n","        train_iters, train_passed  = 0, 0 # инициализируем параметры для процесса обучения\n","        train_loss, train_acc = 0., 0.\n","        start=time.time() # фиксируем время начала обучения\n","\n","        model.train() # переводим модель в режим обучения (чтобы использовать инструментарий типа dropout и bacth normalization)\n","        for X, y in train:  # итерируемся по данным\n","            trainer.zero_grad() # обнуляем старые значения градиентов\n","            y_pred = model(X) # прогоняем данные через модель, получаем предсказания\n","            l = loss(y_pred, y) # вызываем функцию потерь для получения и оценки ошибки (сравниваем с истинными размеченными значениями y - позиция 1 в строке от 0 до 9)\n","            l.backward() # считаем градиенты\n","            trainer.step() # делаем шаг градиентного спуска\n","            train_loss += l.item() # суммируем среднее значение функции потерь на каждом элементе этого батча в этой иттерации\n","            train_acc += (y_pred.argmax(dim=1) == y).sum().item() # находим максимальную (по предсказанной вероятности) позицию в предсказании и сравниваем с позицией верного ответа\n","            # суммируем матрицу и получаем кол-во правильно предсказанных символов - это и есть почти аккураси в этом случае\n","            # т.к. True=1 а False=0\n","            train_iters += 1 # сохраняем кол-во иттераций\n","            train_passed += len(X) # сохраняем, сколько данных прогнали через модель\n","\n"," # делаем такой же цикл для тестовых данных\n","        test_iters, test_passed  = 0, 0\n","        test_loss, test_acc = 0., 0.\n","        model.eval() # переводим в режим исполнения\n","        for X, y in test:\n","           # не обнуляем старые значения градиентов\n","            y_pred = model(X)\n","            l = loss(y_pred, y)\n","             # не считаем градиенты и не делаем шаг градиентного спуска\n","            test_loss += l.item()\n","            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n","            test_iters += 1\n","            test_passed += len(X)\n"," # выводим промежуточные результаты за эпоху\n","        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n","            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n","            test_loss / test_iters, test_acc / test_passed)\n","        )"],"metadata":{"id":"S2X5D9guVre4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVXQq8uaV0LH","executionInfo":{"status":"ok","timestamp":1701133137695,"user_tz":-180,"elapsed":101296,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"9938ccd1-ef27-463b-9fad-d8664c0ccc06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 9.401, train_loss: 1.7227666418603127, train_acc: 0.5743166666666667, test_loss: 1.2695170968770981, test_acc: 0.6527\n","ep: 1, taked: 10.436, train_loss: 1.0629078309586708, train_acc: 0.6712833333333333, test_loss: 0.9384632349014282, test_acc: 0.6734\n","ep: 2, taked: 10.513, train_loss: 0.8600352089455787, train_acc: 0.70425, test_loss: 0.8161783218383789, test_acc: 0.7082\n","ep: 3, taked: 10.200, train_loss: 0.7689622932292045, train_acc: 0.7349666666666667, test_loss: 0.747823429107666, test_acc: 0.7349\n","ep: 4, taked: 9.615, train_loss: 0.7119598233953436, train_acc: 0.7568166666666667, test_loss: 0.7005664236843586, test_acc: 0.7541\n","ep: 5, taked: 10.500, train_loss: 0.6703068266523645, train_acc: 0.77245, test_loss: 0.6648170277476311, test_acc: 0.769\n","ep: 6, taked: 10.459, train_loss: 0.6378206899825563, train_acc: 0.78585, test_loss: 0.63672701343894, test_acc: 0.7796\n","ep: 7, taked: 9.399, train_loss: 0.611764579757731, train_acc: 0.79625, test_loss: 0.6141807787120342, test_acc: 0.7871\n","ep: 8, taked: 9.920, train_loss: 0.5904520998609827, train_acc: 0.8031333333333334, test_loss: 0.5957350164651871, test_acc: 0.7945\n","ep: 9, taked: 10.407, train_loss: 0.5727292076070258, train_acc: 0.8089666666666666, test_loss: 0.5804064847528935, test_acc: 0.7999\n","CPU times: user 1min 39s, sys: 301 ms, total: 1min 40s\n","Wall time: 1min 40s\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Получили вполне приличный результат\n","<br>\n","train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","на самой простейшей сети\n","</font>"],"metadata":{"id":"drmbjYXuYPxS"}},{"cell_type":"code","source":["%%time\n","trainer = torch.optim.Adam(model.parameters(), lr=.01)\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9bNdCMGV0Vy","executionInfo":{"status":"ok","timestamp":1701133316916,"user_tz":-180,"elapsed":108372,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"49aae9f7-5165-403e-dcd7-21a76cb530f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 10.206, train_loss: 0.5789127268689744, train_acc: 0.8133, test_loss: 0.4507943294942379, test_acc: 0.8306\n","ep: 1, taked: 11.018, train_loss: 0.38555354158929056, train_acc: 0.8602666666666666, test_loss: 0.40124305970966817, test_acc: 0.8566\n","ep: 2, taked: 10.869, train_loss: 0.3495318640419777, train_acc: 0.8714166666666666, test_loss: 0.3855059117078781, test_acc: 0.8597\n","ep: 3, taked: 11.459, train_loss: 0.33310477492657115, train_acc: 0.8771, test_loss: 0.3981715518981218, test_acc: 0.8548\n","ep: 4, taked: 9.960, train_loss: 0.3162609485869712, train_acc: 0.88365, test_loss: 0.3847768548876047, test_acc: 0.8608\n","ep: 5, taked: 11.319, train_loss: 0.30223311540928294, train_acc: 0.8883166666666666, test_loss: 0.382225776091218, test_acc: 0.8701\n","ep: 6, taked: 11.131, train_loss: 0.2930746440557723, train_acc: 0.8917166666666667, test_loss: 0.4010060906410217, test_acc: 0.8624\n","ep: 7, taked: 11.093, train_loss: 0.2841165393590927, train_acc: 0.8946166666666666, test_loss: 0.41261614486575127, test_acc: 0.8628\n","ep: 8, taked: 10.484, train_loss: 0.28141077351062854, train_acc: 0.89485, test_loss: 0.3901788979768753, test_acc: 0.8693\n","ep: 9, taked: 10.563, train_loss: 0.27743957530944907, train_acc: 0.8966, test_loss: 0.42043909020721915, test_acc: 0.8605\n","CPU times: user 1min 46s, sys: 337 ms, total: 1min 46s\n","Wall time: 1min 48s\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Применение более продвинутого оптимизатора\n","<br>\n","на самой простейшей сети\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","стало: train_acc: 0.89383, test_acc: 0.8696\n","<br>\n","значительно улучшило результат\n","<br>\n","скорость выполнения замедлилась примерно на 1 сек на слой\n","<br>\n","<br>\n","Добавим еще полносвязных слоев\n","</font>"],"metadata":{"id":"CcEuSl8SYszy"}},{"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Flatten(),\n","    torch.nn.Linear(784, 512),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(512, 256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 128),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(128, 10)\n",")"],"metadata":{"id":"e2ELUsTDYvRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I65dhb_zV0gI","executionInfo":{"status":"ok","timestamp":1701134053502,"user_tz":-180,"elapsed":10,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"5016949a-6058-4e98-dc8a-edaf3233955a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Flatten(start_dim=1, end_dim=-1)\n","  (1): Linear(in_features=784, out_features=512, bias=True)\n","  (2): ReLU()\n","  (3): Linear(in_features=512, out_features=256, bias=True)\n","  (4): ReLU()\n","  (5): Linear(in_features=256, out_features=128, bias=True)\n","  (6): ReLU()\n","  (7): Linear(in_features=128, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["%%time\n","trainer = torch.optim.Adam(model.parameters(), lr=.01)\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkueYBVJZ-jt","executionInfo":{"status":"ok","timestamp":1701134218111,"user_tz":-180,"elapsed":159644,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"c4b274f9-6519-4b94-978a-3c39c93e7def"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 13.652, train_loss: 0.5947571552814321, train_acc: 0.7814, test_loss: 0.4532568156719208, test_acc: 0.8332\n","ep: 1, taked: 13.733, train_loss: 0.39248946030089193, train_acc: 0.8547333333333333, test_loss: 0.40977087095379827, test_acc: 0.8506\n","ep: 2, taked: 14.467, train_loss: 0.35587547186841356, train_acc: 0.8693333333333333, test_loss: 0.38904671296477317, test_acc: 0.8616\n","ep: 3, taked: 18.636, train_loss: 0.33322388897550864, train_acc: 0.8766166666666667, test_loss: 0.37915405035018923, test_acc: 0.8593\n","ep: 4, taked: 17.162, train_loss: 0.33077862497339855, train_acc: 0.8789166666666667, test_loss: 0.39231794103980067, test_acc: 0.8588\n","ep: 5, taked: 15.928, train_loss: 0.3133512649764406, train_acc: 0.8849166666666667, test_loss: 0.39937999844551086, test_acc: 0.8612\n","ep: 6, taked: 15.382, train_loss: 0.3069969519021663, train_acc: 0.8861, test_loss: 0.39864862263202666, test_acc: 0.8611\n","ep: 7, taked: 15.658, train_loss: 0.30354485029869893, train_acc: 0.8884166666666666, test_loss: 0.38946477212011815, test_acc: 0.8644\n","ep: 8, taked: 17.522, train_loss: 0.29329238755905884, train_acc: 0.8915166666666666, test_loss: 0.37508818581700326, test_acc: 0.8672\n","ep: 9, taked: 17.338, train_loss: 0.28657117669886734, train_acc: 0.8939166666666667, test_loss: 0.3694941263645887, test_acc: 0.8711\n","CPU times: user 2min 31s, sys: 467 ms, total: 2min 32s\n","Wall time: 2min 39s\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Дополнительные полносвязные слои\n","<br>\n","улучшили качество сети незначительно\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","было: train_acc: 0.89383, test_acc: 0.8696\n","<br>\n","стало: train_acc: 0.89392, test_acc: 0.8711\n","<br>\n","скорость выполнения замедлилась примерно на одну треть\n","<br>\n","<br>\n","Для улучшения модели добавим слои нормализации\n","</font>"],"metadata":{"id":"caTxQgi7f2u4"}},{"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Flatten(),\n","    torch.nn.Linear(784, 512),\n","    torch.nn.BatchNorm1d(512),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(512, 256),\n","    torch.nn.BatchNorm1d(256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 128),\n","    torch.nn.BatchNorm1d(128),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(128, 10)\n",")"],"metadata":{"id":"TJmFYFPCZ-wE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","trainer = torch.optim.Adam(model.parameters(), lr=.01)\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3i2_NqErZ-6q","executionInfo":{"status":"ok","timestamp":1701134660147,"user_tz":-180,"elapsed":143195,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"88575344-7d83-4012-cfb5-12dda7ddf3f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 14.502, train_loss: 0.4699707555009964, train_acc: 0.8267333333333333, test_loss: 0.4248347692191601, test_acc: 0.8344\n","ep: 1, taked: 14.218, train_loss: 0.3467641055583954, train_acc: 0.8720666666666667, test_loss: 0.39942176584154365, test_acc: 0.8531\n","ep: 2, taked: 14.295, train_loss: 0.3042967079801762, train_acc: 0.8878666666666667, test_loss: 0.40805117608979347, test_acc: 0.85\n","ep: 3, taked: 14.287, train_loss: 0.27624466831379746, train_acc: 0.8978833333333334, test_loss: 0.3563946672715247, test_acc: 0.8685\n","ep: 4, taked: 14.110, train_loss: 0.2520161214026999, train_acc: 0.90585, test_loss: 0.36648095566779376, test_acc: 0.8697\n","ep: 5, taked: 14.252, train_loss: 0.23250088006892103, train_acc: 0.9132, test_loss: 0.3650816443376243, test_acc: 0.8717\n","ep: 6, taked: 14.066, train_loss: 0.21577474639770833, train_acc: 0.9182333333333333, test_loss: 0.37629660964012146, test_acc: 0.874\n","ep: 7, taked: 14.227, train_loss: 0.2018246056551629, train_acc: 0.9247, test_loss: 0.3966965219937265, test_acc: 0.8625\n","ep: 8, taked: 14.441, train_loss: 0.18987474606392232, train_acc: 0.9281333333333334, test_loss: 0.390962353348732, test_acc: 0.873\n","ep: 9, taked: 14.449, train_loss: 0.1778264709926666, train_acc: 0.9321166666666667, test_loss: 0.39200761886313557, test_acc: 0.8742\n","CPU times: user 2min 20s, sys: 369 ms, total: 2min 20s\n","Wall time: 2min 22s\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Добавление слоев нормализации\n","<br>\n","улучшило качество сети\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","было: train_acc: 0.89383, test_acc: 0.8696\n","<br>\n","было: train_acc: 0.89392, test_acc: 0.8711\n","<br>\n","стало: train_acc: 0.93212, test_acc: 0.8742\n","<br>\n","скорость выполнения даже незначительно улучшилась\n","<br>\n","но стало настолько хорошо, что на тренировочных данных похоже что наступает переобучение\n","<br>\n","Посмотрим, сможем ли мы достичь требуемого результата 0.88 просто увеличив число эпох в 2 раза\n","</font>"],"metadata":{"id":"L70zp8Y1hgVN"}},{"cell_type":"code","source":["num_epochs = 20"],"metadata":{"id":"1J-Ky-L7Z_F5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","trainer = torch.optim.Adam(model.parameters(), lr=.01)\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rdMrd1Mjn6c","executionInfo":{"status":"ok","timestamp":1701135484221,"user_tz":-180,"elapsed":297054,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b474c4b4-b63c-402e-9a9a-2fcedc6a0a27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 14.098, train_loss: 0.18096288876964692, train_acc: 0.9312, test_loss: 0.3943815511884168, test_acc: 0.8724\n","ep: 1, taked: 13.953, train_loss: 0.1597659133533214, train_acc: 0.9385833333333333, test_loss: 0.3844720114575466, test_acc: 0.8831\n","ep: 2, taked: 14.020, train_loss: 0.15284970107864826, train_acc: 0.9412, test_loss: 0.4779805944068357, test_acc: 0.8593\n","ep: 3, taked: 14.113, train_loss: 0.1415883183796355, train_acc: 0.9463166666666667, test_loss: 0.46806846123654394, test_acc: 0.8685\n","ep: 4, taked: 14.410, train_loss: 0.13273154015236713, train_acc: 0.9492166666666667, test_loss: 0.49027262661547866, test_acc: 0.8679\n","ep: 5, taked: 14.260, train_loss: 0.12112936215831878, train_acc: 0.95355, test_loss: 0.5097814704407938, test_acc: 0.8672\n","ep: 6, taked: 14.286, train_loss: 0.11202544975788035, train_acc: 0.9572166666666667, test_loss: 0.5215007632854395, test_acc: 0.8737\n","ep: 7, taked: 14.459, train_loss: 0.1079553929573678, train_acc: 0.9593833333333334, test_loss: 0.5162486163841095, test_acc: 0.8727\n","ep: 8, taked: 14.491, train_loss: 0.0996621162333387, train_acc: 0.9617166666666667, test_loss: 0.5445542328059674, test_acc: 0.8748\n","ep: 9, taked: 14.498, train_loss: 0.09614150412380695, train_acc: 0.9631333333333333, test_loss: 0.5457325529307127, test_acc: 0.8757\n","ep: 10, taked: 15.136, train_loss: 0.09171308363054662, train_acc: 0.9651333333333333, test_loss: 0.5541017831357749, test_acc: 0.8771\n","ep: 11, taked: 16.211, train_loss: 0.08863953277468681, train_acc: 0.9657666666666667, test_loss: 0.5641399700194597, test_acc: 0.8782\n","ep: 12, taked: 14.645, train_loss: 0.08015542111181198, train_acc: 0.9687666666666667, test_loss: 0.520731090940535, test_acc: 0.8869\n","ep: 13, taked: 15.948, train_loss: 0.07729466880097034, train_acc: 0.9708333333333333, test_loss: 0.6675841510295868, test_acc: 0.8695\n","ep: 14, taked: 17.721, train_loss: 0.07625995429747916, train_acc: 0.9715833333333334, test_loss: 0.6505281075835228, test_acc: 0.8766\n","ep: 15, taked: 15.146, train_loss: 0.07190582665832752, train_acc: 0.9719166666666667, test_loss: 0.6690809245192213, test_acc: 0.8779\n","ep: 16, taked: 14.548, train_loss: 0.06347825558499452, train_acc: 0.9758833333333333, test_loss: 0.6893202266206572, test_acc: 0.8762\n","ep: 17, taked: 15.231, train_loss: 0.0636638156752637, train_acc: 0.9761833333333333, test_loss: 0.6322896679281257, test_acc: 0.8817\n","ep: 18, taked: 14.746, train_loss: 0.06044870572600593, train_acc: 0.9763833333333334, test_loss: 0.6980729564989361, test_acc: 0.8784\n","ep: 19, taked: 14.829, train_loss: 0.056650438706608526, train_acc: 0.97815, test_loss: 0.724293861258775, test_acc: 0.8817\n","CPU times: user 4min 48s, sys: 833 ms, total: 4min 49s\n","Wall time: 4min 56s\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Увеличение кол-ва эпох в 2 раза\n","<br>\n","позволило нам достичь требуемой точности предсказания сети в 88%\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","было: train_acc: 0.89383, test_acc: 0.8696\n","<br>\n","было: train_acc: 0.89392, test_acc: 0.8711\n","<br>\n","было: train_acc: 0.93212, test_acc: 0.8742\n","<br>\n","стало: train_acc: 0.97815, test_acc: 0.8817\n","<br>\n","времени это заняло в 2 раза больше\n","<br>\n","переобучение на тренировочных данных помешало нам не сильно\n","<br>\n","Посмотрим, могли ли мы улучшить результат просто применив слой Dropout\n","</font>"],"metadata":{"id":"C9fcodLTkQff"}},{"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Flatten(),\n","    torch.nn.Linear(784, 512),\n","    torch.nn.Dropout(0.5),\n","    torch.nn.BatchNorm1d(512),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(512, 256),\n","    torch.nn.BatchNorm1d(256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 128),\n","    torch.nn.BatchNorm1d(128),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(128, 10)\n",")"],"metadata":{"id":"QZcu6CqHjoAI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"1TnBNyhXq9l1"}},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssw2E29xkun6","executionInfo":{"status":"ok","timestamp":1701136095426,"user_tz":-180,"elapsed":336,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"1390b5b8-9292-439d-da48-5a707e36f019"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Flatten(start_dim=1, end_dim=-1)\n","  (1): Linear(in_features=784, out_features=512, bias=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU()\n","  (5): Linear(in_features=512, out_features=256, bias=True)\n","  (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (7): ReLU()\n","  (8): Linear(in_features=256, out_features=128, bias=True)\n","  (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): Linear(in_features=128, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["num_epochs = 10"],"metadata":{"id":"ed-FBfBQnLad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","trainer = torch.optim.Adam(model.parameters(), lr=.01)\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-dhRctBku8l","executionInfo":{"status":"ok","timestamp":1701136284925,"user_tz":-180,"elapsed":147915,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"57cc8cea-f14a-4029-e915-819c215b0734"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 14.260, train_loss: 0.5488258606575905, train_acc: 0.7957833333333333, test_loss: 0.43133625350892546, test_acc: 0.8429\n","ep: 1, taked: 14.150, train_loss: 0.424601237951441, train_acc: 0.8437333333333333, test_loss: 0.3989048205316067, test_acc: 0.8566\n","ep: 2, taked: 14.246, train_loss: 0.39307717478021664, train_acc: 0.8538833333333333, test_loss: 0.3974382795393467, test_acc: 0.8537\n","ep: 3, taked: 14.326, train_loss: 0.3686343227295165, train_acc: 0.8635333333333334, test_loss: 0.41176957711577417, test_acc: 0.8468\n","ep: 4, taked: 14.208, train_loss: 0.3522034965931101, train_acc: 0.8694833333333334, test_loss: 0.393422681465745, test_acc: 0.8543\n","ep: 5, taked: 14.275, train_loss: 0.33778318096982674, train_acc: 0.8744166666666666, test_loss: 0.4011519458144903, test_acc: 0.8525\n","ep: 6, taked: 14.191, train_loss: 0.32470212249045677, train_acc: 0.8794333333333333, test_loss: 0.39112487714737654, test_acc: 0.8574\n","ep: 7, taked: 15.095, train_loss: 0.31779362565659464, train_acc: 0.8821833333333333, test_loss: 0.3940816055983305, test_acc: 0.8528\n","ep: 8, taked: 16.975, train_loss: 0.3103029802758643, train_acc: 0.8838666666666667, test_loss: 0.38628343138843774, test_acc: 0.8623\n","ep: 9, taked: 15.785, train_loss: 0.3015693834487428, train_acc: 0.888, test_loss: 0.4159388830885291, test_acc: 0.8507\n","CPU times: user 2min 22s, sys: 440 ms, total: 2min 23s\n","Wall time: 2min 27s\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4w9jvu4uoET3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Добавление слоя Dropout\n","<br>\n","убрало проблему переобучения, но требуемого параметра точности не достигли\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","было: train_acc: 0.89383, test_acc: 0.8696\n","<br>\n","было: train_acc: 0.89392, test_acc: 0.8711\n","<br>\n","было: train_acc: 0.93212, test_acc: 0.8742\n","<br>\n","стало: train_acc: 0.888, test_acc: 0.8507\n","<br>\n","скорость выполнения не изменилась\n","<br>\n","Посмотрим, изменится ли что нибудь, если мы добавим слой Dropout ближе к голове сети, где связей меньше, а информация \"плотнее\"\n","</font>"],"metadata":{"id":"hx0JWXmDngil"}},{"cell_type":"code","source":[],"metadata":{"id":"f40Ml33FkvFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Flatten(),\n","    torch.nn.Linear(784, 512),\n","    torch.nn.BatchNorm1d(512),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(512, 256),\n","    torch.nn.BatchNorm1d(256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 128),\n","    torch.nn.Dropout(0.5),\n","    torch.nn.BatchNorm1d(128),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(128, 10)\n",")"],"metadata":{"id":"jvSOoJyhoumd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4G_n01e4otMf","executionInfo":{"status":"ok","timestamp":1701136554692,"user_tz":-180,"elapsed":5,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"40bdff5e-875b-4a66-a19c-4a7b69e69bc3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Flatten(start_dim=1, end_dim=-1)\n","  (1): Linear(in_features=784, out_features=512, bias=True)\n","  (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=512, out_features=256, bias=True)\n","  (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (6): ReLU()\n","  (7): Linear(in_features=256, out_features=128, bias=True)\n","  (8): Dropout(p=0.5, inplace=False)\n","  (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): Linear(in_features=128, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["%%time\n","trainer = torch.optim.Adam(model.parameters(), lr=.01)\n","train_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701136726139,"user_tz":-180,"elapsed":143416,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"116153d5-1c21-40ab-a7e0-1106d174789e","id":"WSVgTVcrpD0E"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ep: 0, taked: 14.279, train_loss: 0.5146541495272454, train_acc: 0.81735, test_loss: 0.4185206709429622, test_acc: 0.8446\n","ep: 1, taked: 15.407, train_loss: 0.3761032136830878, train_acc: 0.8660666666666667, test_loss: 0.41394062526524067, test_acc: 0.8479\n","ep: 2, taked: 14.232, train_loss: 0.3276637629625645, train_acc: 0.88175, test_loss: 0.40454412456601857, test_acc: 0.8553\n","ep: 3, taked: 14.302, train_loss: 0.3012321828527654, train_acc: 0.8918833333333334, test_loss: 0.3805054547265172, test_acc: 0.862\n","ep: 4, taked: 14.518, train_loss: 0.2756936955959239, train_acc: 0.9011166666666667, test_loss: 0.36149481013417245, test_acc: 0.8715\n","ep: 5, taked: 14.210, train_loss: 0.2581388068960068, train_acc: 0.90515, test_loss: 0.35508041260764, test_acc: 0.8738\n","ep: 6, taked: 14.181, train_loss: 0.24271697135681802, train_acc: 0.911, test_loss: 0.34506201101467016, test_acc: 0.881\n","ep: 7, taked: 14.194, train_loss: 0.22505057783837015, train_acc: 0.9177666666666666, test_loss: 0.3742091739550233, test_acc: 0.8727\n","ep: 8, taked: 13.973, train_loss: 0.2106957952075816, train_acc: 0.92265, test_loss: 0.35174135528504846, test_acc: 0.8836\n","ep: 9, taked: 13.964, train_loss: 0.1948211097970922, train_acc: 0.9285833333333333, test_loss: 0.3697013106197119, test_acc: 0.882\n","CPU times: user 2min 20s, sys: 384 ms, total: 2min 20s\n","Wall time: 2min 23s\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Добавление слоя Dropout в конец сети\n","<br>\n","повлияло на проблему переобучения не так сильно, но зато мы на 10 эпохах достигли требуемого параметра точности в 88%\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","было: train_acc: 0.89383, test_acc: 0.8696\n","<br>\n","было: train_acc: 0.89392, test_acc: 0.8711\n","<br>\n","было: train_acc: 0.93212, test_acc: 0.8742\n","<br>\n","стало: train_acc: 0.888, test_acc: 0.8507\n","<br>\n","стало: train_acc: 0.92858, test_acc: 0.882\n","<br>\n","скорость выполнения не изменилась\n","<br>\n","Можно сделать вывод, что изменение слоев ближе к голове сети сильнее влияет на результат ее работы.\n","<br>\n","А в целом, главное выдержать правильный баланс.\n","</font>"],"metadata":{"id":"9cO1wVCapH6W"}},{"cell_type":"markdown","source":["Хотелось бы порекомендовать использовать функцию активации выходного слоя. На практике обучение классификатора возможно и без нее, но это хорошая практика, которая иногда позволяет добиться лучших результатов и избежать некоторых проблем, например т.н. “градиентный взрыв”.\n","<br><br>\n","Для бинарной классификации обычно рекомендуют использовать Sigmoid, для многоклассовой - Softmax (хотя можно пробовать и другие варианты):\n","<br><br>\n","\tnn.Sequential(<br><br>\n","\tnn.Flatten(),<br>\n","\tnn.Linear(784, 256),<br>\n","\tnn.ReLU(),<br>\n","\tnn.Linear(256, 10),<br>\n","\tnn.Softmax()<br>\n",")<br><br>\n","Линейные слои могут возвращать любые значения, как положительные, так и отрицательные, а также очень большие, в то время как softmax и sigmoid нормируют их в диапазон от 0 до 1.\n","\n","<br>"],"metadata":{"id":"pSdtTMDM2miL"}},{"cell_type":"code","source":[],"metadata":{"id":"9koBgANOotUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JNiRY6dSotc0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Это шаблон примечания\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"Bh6nSH0dAjWq"}}]}