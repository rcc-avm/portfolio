{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMqMgylhhyb8Fd78z96on39"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Домашнее задание по теме «Свёрточные сети»<br>\n","Цель задания:<br>\n"," научиться базово подбирать архитектуру, строить и обучать свёрточные нейронные сети для решения задачи классификации.\n","<br><br>\n","Контекст\n","Это домашнее задание по сути является продолжением предыдущего. В нём вы меняете архитектуру сети с полносвязной на свёрточную.\n","<br><br>\n","Задание<br>\n","Постройте модель, используя архитектуру со свёрточными слоями, для классификации Fashion MNIST. Итоговое качество (accuracy) должно быть не ниже 89,5.\n","<br><br>\n","Инструкция к выполнению задания\n","<br><br>\n","Скачайте тренировочную и тестовою часть датасета Fashion <br>\n","Постройте архитектуру модели, используя свёрточные слои, слои регуляризации и один финальный полносвязный слой<br>\n","Обучите модель до необходимого качества. <br>Если сеть не обучается до необходимого качества, попробуйте поменять архитектуру сети, варьируя параметры свёрток, количество каналов, количество свёрточных слоёв, слои регуляризации, тип оптимайзера и т. д.<br><br>\n","Формат сдачи работы<br>\n","Прикрепите ссылку на готовое решение в личном кабинете. Работу можно отправлять в виде ссылки на python-ноутбук из GitHub, Google Colaboratory или аналогичных платформ. Не забудьте открыть доступ на просмотр и комментирование.<br><br>\n","\n","Критерии оценивания<br>\n","По итогу выполнения задания вы получите зачёт.<br>\n","\n","Задание считается выполненным, если:<br>\n","\n","корректно получены трейн и тест части<br>\n","сеть обучается<br>\n","итоговое качество на тестовой выборке выше указанного в задании<br>\n"],"metadata":{"id":"x32OG7Op9ba7"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","import time\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from torchsummary import summary\n","\n","import torchvision as tv\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"bgos6fNw9cBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE=256"],"metadata":{"id":"thl39QLl-mmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = tv.datasets.FashionMNIST(root = '.', train = True, download=True, transform=tv.transforms.ToTensor())\n","test_dataset = tv.datasets.FashionMNIST(root = '.', train = False, download=True, transform=tv.transforms.ToTensor())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGgJ_6qRCoZe","executionInfo":{"status":"ok","timestamp":1701341223260,"user_tz":-180,"elapsed":6724,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"95c879e7-4631-4207-d5e8-295239b09150"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:02<00:00, 13148731.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 211229.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3875827.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 12359631.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"MCUwug_FD3qU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0][0].shape"],"metadata":{"id":"-ZivcBZKAkut","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701341223261,"user_tz":-180,"elapsed":41,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b0c53c00-0215-451e-b17c-ce0e7ce4b5ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["28*28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wu3T_8UyVVct","executionInfo":{"status":"ok","timestamp":1701341223765,"user_tz":-180,"elapsed":539,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"ba960b9d-f357-4f5e-829a-f232a750b6d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["784"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["model_x = torch.nn.Sequential(\n","    torch.nn.Flatten(), # вытягиваем в вектор\n","    torch.nn.Linear(784, 256), # полносвязный слой с входом 28х28=784 и выходом 256\n","    torch.nn.ReLU(), # функция активации\n","    torch.nn.Linear(256, 10) # полносвязный слой с входом 256 и выходом 10 - каждый нейрон отвечает за свою цифру/класс\n",")"],"metadata":{"id":"RspV8EfxAk7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(model_x, input_size=(1, 28, 28), batch_size=BATCH_SIZE, device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlfquLfoqif5","executionInfo":{"status":"ok","timestamp":1701341223766,"user_tz":-180,"elapsed":67,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"93033b6c-3760-45d7-a4f8-b6999cd4fdc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","           Flatten-1                 [256, 784]               0\n","            Linear-2                 [256, 256]         200,960\n","              ReLU-3                 [256, 256]               0\n","            Linear-4                  [256, 10]           2,570\n","================================================================\n","Total params: 203,530\n","Trainable params: 203,530\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.77\n","Forward/backward pass size (MB): 2.55\n","Params size (MB): 0.78\n","Estimated Total Size (MB): 4.09\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["<font color=green size=3>\n","<br>\n","В описании, что выше, плюс в том, что и функции, как и слои, отображаются в распечатке модели.\n","<br>\n","Но если функции будут более замысловатые, они не отобразятся слоями, и возможно только запутают.\n","<br>\n","Функции лучше смотреть в методе forward.\n","</font>"],"metadata":{"id":"Ftz-C_i1AgcF"}},{"cell_type":"code","source":["class FshnLinF(nn.Module):\n","    def __init__(self):\n","        #super(FshnLinF, self).__init__()\n","        super().__init__()\n","\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(784, 256, bias=True)\n","        self.fc2 = nn.Linear(256, 10, bias=True)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"EKFfO1kWlugn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n","<br>\n","Будем использовать такое описание модели, как с одной стороны краткое, а с другой стороны - гибкое.\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"-iWEGcDbA2or"}},{"cell_type":"code","source":["model = FshnLinF()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6__FXF9-8oTW","executionInfo":{"status":"ok","timestamp":1701341223766,"user_tz":-180,"elapsed":62,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"e86a2a7b-c98b-46ac-8461-2b8f98008c15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnLinF(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=784, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["BATCH_SIZE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEbNdslovRVa","executionInfo":{"status":"ok","timestamp":1701341223767,"user_tz":-180,"elapsed":58,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"e4fc1599-24dd-4ef9-c5f1-b7f27f6a2d49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["256"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["summary(model, input_size=(1, 28, 28), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvY-T6nOq_Cz","executionInfo":{"status":"ok","timestamp":1701341223767,"user_tz":-180,"elapsed":52,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"43622ee7-9c46-4196-9874-7749b4ff816c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","           Flatten-1                  [-1, 784]               0\n","            Linear-2                  [-1, 256]         200,960\n","            Linear-3                   [-1, 10]           2,570\n","================================================================\n","Total params: 203,530\n","Trainable params: 203,530\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.78\n","Estimated Total Size (MB): 0.79\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","trainer = torch.optim.SGD(model.parameters(), lr=.01) # оптимайзер функции потерь (передали туда параметры и шаг обучения) - схокастический градиентный спуск\n","num_epochs = 10 # кол-во эпох"],"metadata":{"id":"Sibz_9wLAlPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # обучаем модель\n","def train_model():\n","    for ep in range(num_epochs):\n","        train_iters, train_passed  = 0, 0 # инициализируем параметры для процесса обучения\n","        train_loss, train_acc = 0., 0.\n","        start=time.time() # фиксируем время начала обучения\n","\n","        model.train() # переводим модель в режим обучения (чтобы использовать инструментарий типа dropout и bacth normalization)\n","        for X, y in train:  # итерируемся по данным\n","            trainer.zero_grad() # обнуляем старые значения градиентов\n","            y_pred = model(X) # прогоняем данные через модель, получаем предсказания\n","            l = loss(y_pred, y) # вызываем функцию потерь для получения и оценки ошибки (сравниваем с истинными размеченными значениями y - позиция 1 в строке от 0 до 9)\n","            l.backward() # считаем градиенты\n","            trainer.step() # делаем шаг градиентного спуска\n","            train_loss += l.item() # суммируем среднее значение функции потерь на каждом элементе этого батча в этой иттерации\n","            train_acc += (y_pred.argmax(dim=1) == y).sum().item() # находим максимальную (по предсказанной вероятности) позицию в предсказании и сравниваем с позицией верного ответа\n","            # суммируем матрицу и получаем кол-во правильно предсказанных символов - это и есть почти аккураси в этом случае\n","            # т.к. True=1 а False=0\n","            train_iters += 1 # сохраняем кол-во иттераций\n","            train_passed += len(X) # сохраняем, сколько данных прогнали через модель\n","\n"," # делаем такой же цикл для тестовых данных\n","        test_iters, test_passed  = 0, 0\n","        test_loss, test_acc = 0., 0.\n","        model.eval() # переводим в режим исполнения\n","        for X, y in test:\n","           # не обнуляем старые значения градиентов\n","            y_pred = model(X)\n","            l = loss(y_pred, y)\n","             # не считаем градиенты и не делаем шаг градиентного спуска\n","            test_loss += l.item()\n","            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n","            test_iters += 1\n","            test_passed += len(X)\n"," # выводим промежуточные результаты за эпоху\n","        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n","            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n","            test_loss / test_iters, test_acc / test_passed)\n","        )"],"metadata":{"id":"S2X5D9guVre4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%%time\n","#train_model()"],"metadata":{"id":"wVXQq8uaV0LH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Получили вполне приличный результат\n","<br>\n","train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","на самой простейшей сети из полносвязных слоев\n","<br>\n","<br>\n","Теперь переделаем модель с использованием сверточных слоев\n","<br>\n","Добавим два сверточных слоя, а полносвязную голову оставим для классификации\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"drmbjYXuYPxS"}},{"cell_type":"code","source":["class FshnConLinF(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n","\n","    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n","    self.fc2 = nn.Linear(in_features=120, out_features=60)\n","    self.out = nn.Linear(in_features=60, out_features=10)\n","\n","  def forward(self, x):\n","    # conv 1\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # fc1\n","    x = x.reshape(-1, 12*4*4)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","\n","    # fc2\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","\n","    # output\n","    x = self.out(x)\n","    # don't need softmax here since we'll use cross-entropy as activation.\n","    # наша функция потерь- кросэнтропия, которая и применяет внутри себя функцию софтмакс при расчете ошибки для расчета градиентов\n","    return x"],"metadata":{"id":"rYvOi4WXh23I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Схема такая:\n","<br>\n","256 - наш размер батча, но дальше  пишем все для одного имиджа\n","<br>\n","1@28x28 - разм. входящего имиджа\n","<br>\n","6@24x24 - первая свертка с ядром 5 (результат)\n","<br>\n","6@12x12 - первый макспуллинг паддинг 2 шаг 2\n","<br>\n","12@8x8 - вторая свертка с ядром 5\n","<br>\n","12@4x4 - второй макспуллинг паддинг 2 шаг 2\n","<br>\n","12@4x4 решейпим (reshape) в 1x192 на входе - первый полносвязный слой (обошлись без Flatten и без MaxPulling в 1x1), получили 1x120 на выходе\n","<br>\n","1x120 -> 1x60 - второй полносвязны слой\n","<br>\n","1x60 -> 1x10 - третий полносвязный слой с выходом 10 классов\n","<br>\n","\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"U5lcIzQTB69I"}},{"cell_type":"code","source":["model = FshnConLinF()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"anoCrEo6h3M8","executionInfo":{"status":"ok","timestamp":1701341223771,"user_tz":-180,"elapsed":47,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"cb861a8d-6c02-47ec-ecfb-bfbbb00316b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnConLinF(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=192, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (out): Linear(in_features=60, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["summary(model, input_size=(1, 28, 28), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hlHAbkqrSUH","executionInfo":{"status":"ok","timestamp":1701341223772,"user_tz":-180,"elapsed":41,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"be01cacf-dfc6-45d5-f914-fa08e11a9f1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 24, 24]             156\n","            Conv2d-2             [-1, 12, 8, 8]           1,812\n","            Linear-3                  [-1, 120]          23,160\n","            Linear-4                   [-1, 60]           7,260\n","            Linear-5                   [-1, 10]             610\n","================================================================\n","Total params: 32,998\n","Trainable params: 32,998\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.03\n","Params size (MB): 0.13\n","Estimated Total Size (MB): 0.16\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","trainer = torch.optim.SGD(model.parameters(), lr=.01) # оптимайзер функции потерь (передали туда параметры и шаг обучения) - схокастический градиентный спуск\n","num_epochs = 10 # кол-во эпох"],"metadata":{"id":"2ICpGTeEqvoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%%time\n","#train_model()"],"metadata":{"id":"QRBj7slPq2Ee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n"," Результат комбинированной модели слабее,чем был только на двух полносвязных слоях.\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","стало: train_acc: 0.71612, test_acc: 0.7266\n","<br>\n","<br>\n","Плюсом можно считать равномерные результаты на обучающей и тестовой выборках.\n","<br>\n","Возможно при длительном обучении это позволит лучше  обучиться.\n","<br>\n","Видим, что число параметров кардинально (на порядок) сократилось, а время обучения в два раза увеличилось. Памяти расходуется меньше, но расчетов требуется больше.\n","<br>\n","Посмотрим, что изменится, если перенести расчеты на GPU\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"iYX2gbQ98XZ5"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # переключаемся, если доступно\n","device"],"metadata":{"id":"JNiRY6dSotc0","executionInfo":{"status":"ok","timestamp":1701341223773,"user_tz":-180,"elapsed":35,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"7c70132f-7047-4132-cbf1-450bf5723666"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def train_device(net, train_iter, test_iter, optimizer, num_epochs, device):\n","    loss = nn.CrossEntropyLoss()\n","\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","\n","        for X, y in train_iter:\n","            X, y = X.to(device), y.to(device) # перекладываем данные на GPU\n","            optimizer.zero_grad()\n","            y_hat = net(X)\n","            l = loss(y_hat, y)\n","            l.backward()\n","            optimizer.step()\n","            train_l_sum += l.item()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","            n += y.shape[0]\n","\n","        test_acc = evaluate_accuracy_device(test_iter, net, device)\n","        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}' \\\n","              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"],"metadata":{"id":"lVGNYWP4BpiV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:44.014332Z","start_time":"2019-11-14T21:43:44.006081Z"},"id":"luDfZTfjxX3j"},"outputs":[],"source":["def evaluate_accuracy_device(data_iter, net, device):  # передаем текущее устройство\n","    acc_sum, n = torch.Tensor([0]).to(device), 0  # переводим на него тензор аккураси\n","    for X, y in data_iter:\n","        X, y = X.to(device), y.to(device) # переводим на него тензора данных\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\n","        n += y.shape[0]\n","    return acc_sum.item() / n"]},{"cell_type":"code","source":["model = FshnConLinF()"],"metadata":{"id":"MeHg-dc4G2Pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:43.987680Z","start_time":"2019-11-14T21:43:43.982555Z"},"id":"3DSc7YPtxClu"},"outputs":[],"source":["model = model.to(device) # перекладываем модель на GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:44:50.015770Z","start_time":"2019-11-14T21:43:44.017767Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"gRP8hgY1xedj","outputId":"74be5087-20ef-4738-f000-027231965bde","executionInfo":{"status":"ok","timestamp":1701341230161,"user_tz":-180,"elapsed":60,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 402 µs, sys: 0 ns, total: 402 µs\n","Wall time: 410 µs\n"]}],"source":["%%time\n","loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","lr, num_epochs = 0.01, 20\n","trainer = torch.optim.SGD(model.parameters(), lr=lr)\n","#train_device(model, train, test, trainer, num_epochs, device)"]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Скорость расчета на GPU возросла примерно в 2 раза.\n","<br>\n","Считается чуть быстрее, чем считались 2 полносвязных слоя на CPU. Т.е. очень приемлемо.\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","было при 10 эпохах: train_acc: 0.71612, test_acc: 0.7266\n","<br>\n","стало при 20 эпохах: train acc 0.800, test acc 0.797\n","<br>\n","<br>\n","Потенциал обучения по прежнему хороший. На 20 эпохах результат догнал целиком полносвязную сеть и может обучаться дальше.\n","<br>\n","Попробуем за счет добавления дополнительных сверток/каналов/параметров поднять скорость обучения.\n","<br>\n","\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"p4IbnjziKYFw"}},{"cell_type":"code","source":["class FshnConPlusLinF(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=1)\n","    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n","\n","    self.fc1 = nn.Linear(in_features=120, out_features=90)\n","    self.fc2 = nn.Linear(in_features=90, out_features=60)\n","    self.out = nn.Linear(in_features=60, out_features=10)\n","\n","  def forward(self, x):\n","    # conv 1\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 3\n","    x = self.conv3(x)\n","\n","    # fc1\n","    x = x.reshape(-1, 120)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","\n","    # fc2\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","\n","    # output\n","    x = self.out(x)\n","    # don't need softmax here since we'll use cross-entropy as activation.\n","    return x"],"metadata":{"id":"M0KMcDm8mTbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = FshnConPlusLinF()\n","print(model1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Egkn0crbl-FG","executionInfo":{"status":"ok","timestamp":1701341230162,"user_tz":-180,"elapsed":56,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"4a6b0bdc-0bb1-4924-82d4-904d2aebf584"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnConPlusLinF(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=120, out_features=90, bias=True)\n","  (fc2): Linear(in_features=90, out_features=60, bias=True)\n","  (out): Linear(in_features=60, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["summary(model1, input_size=(1, 28, 28), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701341230162,"user_tz":-180,"elapsed":51,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"e2977230-a89e-4390-8d66-99fa51e87567","id":"qnzolHfsp5g3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 26, 26]             156\n","            Conv2d-2           [-1, 16, 11, 11]           2,416\n","            Conv2d-3            [-1, 120, 1, 1]          48,120\n","            Linear-4                   [-1, 90]          10,890\n","            Linear-5                   [-1, 60]           5,460\n","            Linear-6                   [-1, 10]             610\n","================================================================\n","Total params: 67,652\n","Trainable params: 67,652\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.05\n","Params size (MB): 0.26\n","Estimated Total Size (MB): 0.31\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["# <font color=green size=3>\n","За счет вставленного 3 сверточного слоя подняли кол-во каналов до 120 и кол-во параметров с 33 до 67 тысяч.\n","<br>\n","Возможно сеть это улучшило, но на скорости обучения никак не сказалось.\n","<br>\n","</font>"],"metadata":{"id":"l1vgJgymu5ci"}},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:43.987680Z","start_time":"2019-11-14T21:43:43.982555Z"},"id":"Q2Pl1d09t9QI"},"outputs":[],"source":["model1 = model1.to(device) # перекладываем модель на GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:44:50.015770Z","start_time":"2019-11-14T21:43:44.017767Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c5c5ec5a-7b08-4a89-9e3d-75d091d506b6","executionInfo":{"status":"ok","timestamp":1701341230163,"user_tz":-180,"elapsed":48,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"id":"Itn_WK88uNFC"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 628 µs, sys: 0 ns, total: 628 µs\n","Wall time: 556 µs\n"]}],"source":["%%time\n","loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","lr, num_epochs = 0.01, 10\n","trainer = torch.optim.SGD(model1.parameters(), lr=lr)\n","#train_device(model1, train, test, trainer, num_epochs, device)"]},{"cell_type":"code","source":["class FshnConPlus2LinF(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=1)\n","    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n","\n","    self.bn1 = nn.BatchNorm1d(120)\n","    self.fc1 = nn.Linear(in_features=120, out_features=90)\n","    self.fc2 = nn.Linear(in_features=90, out_features=60)\n","    self.out = nn.Linear(in_features=60, out_features=10)\n","\n","\n","  def forward(self, x):\n","    # conv 1\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 3\n","    x = self.conv3(x)\n","\n","    # fc1\n","    x = x.reshape(-1, 120)\n","    x = self.bn1(x)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","\n","    # fc2\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","\n","    # output\n","    x = self.out(x)\n","    # don't need softmax here since we'll use cross-entropy as activation.\n","    return x"],"metadata":{"id":"Ek419DOR3IdL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = FshnConPlus2LinF()\n","print(model2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701341230164,"user_tz":-180,"elapsed":44,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"9e549184-5c6b-4298-90c6-5f93dd7b77cb","id":"0xqLAwJs3mIH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnConPlus2LinF(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","  (bn1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=120, out_features=90, bias=True)\n","  (fc2): Linear(in_features=90, out_features=60, bias=True)\n","  (out): Linear(in_features=60, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:43.987680Z","start_time":"2019-11-14T21:43:43.982555Z"},"id":"to7oMrmW4tVw"},"outputs":[],"source":["model2 = model2.to(device) # перекладываем модель на GPU"]},{"cell_type":"code","source":["summary(model2, input_size=(1, 28, 28), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701341237440,"user_tz":-180,"elapsed":7315,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"a744751d-c5e7-42d4-94cc-bb36222fa084","id":"LnAUC6CO30Rr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 26, 26]             156\n","            Conv2d-2           [-1, 16, 11, 11]           2,416\n","            Conv2d-3            [-1, 120, 1, 1]          48,120\n","       BatchNorm1d-4                  [-1, 120]             240\n","            Linear-5                   [-1, 90]          10,890\n","            Linear-6                   [-1, 60]           5,460\n","            Linear-7                   [-1, 10]             610\n","================================================================\n","Total params: 67,892\n","Trainable params: 67,892\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.05\n","Params size (MB): 0.26\n","Estimated Total Size (MB): 0.31\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:44:50.015770Z","start_time":"2019-11-14T21:43:44.017767Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b121ffa-43fb-4a4c-ea6a-6645c07fafbf","executionInfo":{"status":"ok","timestamp":1701341237442,"user_tz":-180,"elapsed":64,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"id":"NYpgdDIE40ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 0 ns, sys: 319 µs, total: 319 µs\n","Wall time: 317 µs\n"]}],"source":["%%time\n","loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","lr, num_epochs = 0.01, 10\n","trainer = torch.optim.SGD(model2.parameters(), lr=lr)\n","#train_device(model2, train, test, trainer, num_epochs, device)"]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Между сверточными слоями и головой добавили 1 слой нормализации и скорость обучения возросла кардинально.\n","<br>\n","полносвязный вариант\n","<br>\n","было: train_acc: 0.80975, test_acc: 0.7988\n","<br>\n","комбинированный вариант с 2 сверточными слоями\n","<br>\n","было: при 10 эпохах: train_acc: 0.71612, test_acc: 0.7266\n","<br>\n","было: при 20 эпохах: train acc 0.800, test acc 0.0.797\n","<br>\n","комбинированный с 3 сверточными слоями\n","<br>\n","было: при 10 эпохах: train acc 0.719, test acc 0.693\n","<br>\n","комбинированный с 3 сверточными слоями и нормализацией\n","<br>\n","стало: при 10 эпохах acc 0.881, test acc 0.873\n","<br>\n","<br>\n","<br>\n","Потенциал обучения по прежнему хороший.\n","<br>\n","Уберем лишние полносвязные слои.\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"rXyjqstfuZYa"}},{"cell_type":"code","source":["class FshnConPlus3LinF(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=1)\n","    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n","\n","    self.bn1 = nn.BatchNorm1d(120)\n","    self.out = nn.Linear(in_features=120, out_features=10)\n","\n","\n","  def forward(self, x):\n","    # conv 1\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 3\n","    x = self.conv3(x)\n","\n","    # output\n","    x = x.reshape(-1, 120)\n","    x = self.bn1(x)\n","    x = self.out(x)\n","    # don't need softmax here since we'll use cross-entropy as activation.\n","    return x"],"metadata":{"id":"dueiDUaJ1s88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model3 = FshnConPlus3LinF()\n","print(model3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701341237443,"user_tz":-180,"elapsed":61,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b0a835c2-a1e8-4ae8-fb68-d396a30fbf6a","id":"u16318uW3Md4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnConPlus3LinF(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","  (bn1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (out): Linear(in_features=120, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:43.987680Z","start_time":"2019-11-14T21:43:43.982555Z"},"id":"EF3GETeA3XJa"},"outputs":[],"source":["model3 = model3.to(device) # перекладываем модель на GPU"]},{"cell_type":"code","source":["summary(model3, input_size=(1, 28, 28), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701341237443,"user_tz":-180,"elapsed":55,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"39a43fdd-4c47-4be0-d72c-7cc5cd714d78","id":"3C1-MYfi3gei"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 26, 26]             156\n","            Conv2d-2           [-1, 16, 11, 11]           2,416\n","            Conv2d-3            [-1, 120, 1, 1]          48,120\n","       BatchNorm1d-4                  [-1, 120]             240\n","            Linear-5                   [-1, 10]           1,210\n","================================================================\n","Total params: 52,142\n","Trainable params: 52,142\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.05\n","Params size (MB): 0.20\n","Estimated Total Size (MB): 0.25\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:44:50.015770Z","start_time":"2019-11-14T21:43:44.017767Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ff02b1b-c924-4f38-9ab6-7ca5816fbcfc","executionInfo":{"status":"ok","timestamp":1701341237444,"user_tz":-180,"elapsed":52,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"id":"bAF0-oZq3tQc"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 265 µs, sys: 79 µs, total: 344 µs\n","Wall time: 352 µs\n"]}],"source":["%%time\n","loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","lr, num_epochs = 0.01, 10\n","trainer = torch.optim.SGD(model3.parameters(), lr=lr)\n","#train_device(model3, train, test, trainer, num_epochs, device)"]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Странно, но удаление двух полносвязных слоев и всех их функций активации похоже никак не сказалось на скорости обучения.\n","<br>\n","Видимо 3 сверточных слоев и слоя нормализации уже хватает что бы все спорядковать и на долю полносвязных слоев \"работы\" уже не остается.\n","<br>\n","Скорость выполнения похоже зависит от загрузки Гугла и не является показателем, т.к. должна была возрасти из-за уменьшения параметров, а по факту упала.\n","<br>\n","<br>\n","вставим дополнительные слои нормализации между слоями сверток.\n","<br>\n","</font>"],"metadata":{"id":"0fGXH6ed5qcA"}},{"cell_type":"code","source":["class FshnConPlus4LinF(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=1)\n","    self.bn1 = nn.BatchNorm2d(6)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=1)\n","    self.bn2 = nn.BatchNorm2d(16)\n","    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n","\n","    self.bn3 = nn.BatchNorm1d(120)\n","    self.out = nn.Linear(in_features=120, out_features=10)\n","\n","\n","  def forward(self, x):\n","    # conv 1\n","    #x = self.conv1(x)\n","    x = self.bn1(self.conv1(x))\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    #x = self.conv2(x)\n","    x = self.bn2(self.conv2(x))\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 3\n","    x = self.conv3(x)\n","\n","    # output\n","    x = x.reshape(-1, 120)\n","    x = self.bn3(x)\n","    x = self.out(x)\n","    # don't need softmax here since we'll use cross-entropy as activation.\n","    return x"],"metadata":{"id":"FStzX6p_6_w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model4 = FshnConPlus4LinF()\n","print(model4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701342389986,"user_tz":-180,"elapsed":287,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"6d094fbf-b3f3-4a89-8d2c-fb4c64cbb64f","id":"273xXSgD6_xN"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnConPlus4LinF(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","  (bn3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (out): Linear(in_features=120, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:43.987680Z","start_time":"2019-11-14T21:43:43.982555Z"},"id":"GTIrqf646_xO"},"outputs":[],"source":["model4 = model4.to(device) # перекладываем модель на GPU"]},{"cell_type":"code","source":["summary(model4, input_size=(1, 28, 28), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701342415787,"user_tz":-180,"elapsed":374,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"ba4dde7a-29d7-46f3-ed83-34e54a6bfa61","id":"bxuNhdi06_xP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 26, 26]             156\n","       BatchNorm2d-2            [-1, 6, 26, 26]              12\n","            Conv2d-3           [-1, 16, 11, 11]           2,416\n","       BatchNorm2d-4           [-1, 16, 11, 11]              32\n","            Conv2d-5            [-1, 120, 1, 1]          48,120\n","       BatchNorm1d-6                  [-1, 120]             240\n","            Linear-7                   [-1, 10]           1,210\n","================================================================\n","Total params: 52,186\n","Trainable params: 52,186\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.09\n","Params size (MB): 0.20\n","Estimated Total Size (MB): 0.30\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:44:50.015770Z","start_time":"2019-11-14T21:43:44.017767Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f44b096-8403-44fe-8f9c-8146a1694823","executionInfo":{"status":"ok","timestamp":1701342528742,"user_tz":-180,"elapsed":89785,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"id":"8P7DkoYs6_xP"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1, loss 0.0028, train acc 0.773, test acc 0.817, time 8.3 sec\n","epoch 2, loss 0.0019, train acc 0.842, test acc 0.842, time 9.3 sec\n","epoch 3, loss 0.0016, train acc 0.859, test acc 0.854, time 10.6 sec\n","epoch 4, loss 0.0015, train acc 0.870, test acc 0.863, time 9.2 sec\n","epoch 5, loss 0.0014, train acc 0.877, test acc 0.868, time 9.0 sec\n","epoch 6, loss 0.0013, train acc 0.882, test acc 0.873, time 9.0 sec\n","epoch 7, loss 0.0013, train acc 0.886, test acc 0.875, time 8.2 sec\n","epoch 8, loss 0.0012, train acc 0.890, test acc 0.878, time 9.0 sec\n","epoch 9, loss 0.0012, train acc 0.894, test acc 0.880, time 9.0 sec\n","epoch 10, loss 0.0012, train acc 0.896, test acc 0.879, time 8.1 sec\n","CPU times: user 1min 27s, sys: 350 ms, total: 1min 27s\n","Wall time: 1min 29s\n"]}],"source":["%%time\n","loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","lr, num_epochs = 0.01, 10\n","trainer = torch.optim.SGD(model4.parameters(), lr=lr)\n","train_device(model4, train, test, trainer, num_epochs, device)"]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Добавление двух слоев нормализации между сверточными слоями увеличила скорость обучения.\n","<br>\n","после 6 эпохи уже получили\n","<br>\n","train acc 0.882, test acc 0.873, time 9.0 sec\n","<br>\n","а после 10 эпохи\n","<br>\n","train acc 0.896, test acc 0.879, time 8.1 sec\n","<br>\n","Попробуем заменить первый сверточный слой с ядром 5х5 на 2 слоя 3х3 и еще добавить каналов.\n","<br>\n","\n","</font>"],"metadata":{"id":"dnvBzzEw2zrv"}},{"cell_type":"code","source":["class FshnConPlus5LinF(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv11 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding=1)\n","    self.conv12 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=0)\n","\n","    self.bn1 = nn.BatchNorm2d(20)\n","    self.conv2 = nn.Conv2d(in_channels=20, out_channels=30, kernel_size=5, padding=1)\n","    self.bn2 = nn.BatchNorm2d(30)\n","    self.conv3 = nn.Conv2d(in_channels=30, out_channels=240, kernel_size=5)\n","\n","    self.bn3 = nn.BatchNorm1d(240)\n","    self.out = nn.Linear(in_features=240, out_features=10)\n","\n","\n","  def forward(self, x):\n","    # conv 1\n","    x = self.conv11(x)\n","    x = self.bn1(self.conv12(x))\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 2\n","    #x = self.conv2(x)\n","    x = self.bn2(self.conv2(x))\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, kernel_size=2, stride=2)\n","\n","    # conv 3\n","    x = self.conv3(x)\n","\n","    # output\n","    x = x.reshape(-1, 240)\n","    x = self.bn3(x)\n","    x = self.out(x)\n","    # don't need softmax here since we'll use cross-entropy as activation.\n","    # наша функция потерь- кросэнтропия, которая и применяет внутри себя функцию софтмакс при расчете ошибки для расчета градиентов\n","    return x"],"metadata":{"id":"3he_RRoP2zsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model5 = FshnConPlus5LinF()\n","print(model5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701342945309,"user_tz":-180,"elapsed":247,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"e6320db6-347c-4020-c8f5-2512b9d9e1ce","id":"LEiKNq5F2zsF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FshnConPlus5LinF(\n","  (conv11): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv12): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n","  (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(30, 240, kernel_size=(5, 5), stride=(1, 1))\n","  (bn3): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (out): Linear(in_features=240, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:43:43.987680Z","start_time":"2019-11-14T21:43:43.982555Z"},"id":"kBMjE7aI2zsG"},"outputs":[],"source":["model5 = model5.to(device) # перекладываем модель на GPU"]},{"cell_type":"code","source":["summary(model5, input_size=(1, 28, 28), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701342982066,"user_tz":-180,"elapsed":237,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"a0644fe9-ec16-4d83-9106-f6be329a20d7","id":"bDDFNue-2zsH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 10, 28, 28]             100\n","            Conv2d-2           [-1, 20, 26, 26]           1,820\n","       BatchNorm2d-3           [-1, 20, 26, 26]              40\n","            Conv2d-4           [-1, 30, 11, 11]          15,030\n","       BatchNorm2d-5           [-1, 30, 11, 11]              60\n","            Conv2d-6            [-1, 240, 1, 1]         180,240\n","       BatchNorm1d-7                  [-1, 240]             480\n","            Linear-8                   [-1, 10]           2,410\n","================================================================\n","Total params: 200,180\n","Trainable params: 200,180\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.33\n","Params size (MB): 0.76\n","Estimated Total Size (MB): 1.09\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-11-14T21:44:50.015770Z","start_time":"2019-11-14T21:43:44.017767Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"887327f8-ab83-4e09-8d57-ab71e1af4437","executionInfo":{"status":"ok","timestamp":1701343657043,"user_tz":-180,"elapsed":546289,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"id":"u_6xeyqD2zsI"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1, loss 0.0023, train acc 0.810, test acc 0.850, time 11.1 sec\n","epoch 2, loss 0.0015, train acc 0.869, test acc 0.868, time 10.9 sec\n","epoch 3, loss 0.0013, train acc 0.883, test acc 0.875, time 10.6 sec\n","epoch 4, loss 0.0012, train acc 0.893, test acc 0.882, time 11.0 sec\n","epoch 5, loss 0.0011, train acc 0.899, test acc 0.886, time 11.0 sec\n","epoch 6, loss 0.0011, train acc 0.904, test acc 0.890, time 11.0 sec\n","epoch 7, loss 0.0010, train acc 0.908, test acc 0.891, time 10.7 sec\n","epoch 8, loss 0.0010, train acc 0.913, test acc 0.895, time 10.5 sec\n","epoch 9, loss 0.0009, train acc 0.915, test acc 0.895, time 11.0 sec\n","epoch 10, loss 0.0009, train acc 0.918, test acc 0.896, time 11.2 sec\n","epoch 11, loss 0.0009, train acc 0.921, test acc 0.899, time 11.0 sec\n","epoch 12, loss 0.0009, train acc 0.924, test acc 0.899, time 10.8 sec\n","epoch 13, loss 0.0008, train acc 0.926, test acc 0.900, time 10.5 sec\n","epoch 14, loss 0.0008, train acc 0.928, test acc 0.901, time 11.0 sec\n","epoch 15, loss 0.0008, train acc 0.930, test acc 0.901, time 11.1 sec\n","epoch 16, loss 0.0008, train acc 0.932, test acc 0.901, time 11.1 sec\n","epoch 17, loss 0.0007, train acc 0.934, test acc 0.901, time 10.8 sec\n","epoch 18, loss 0.0007, train acc 0.935, test acc 0.901, time 10.4 sec\n","epoch 19, loss 0.0007, train acc 0.937, test acc 0.900, time 11.0 sec\n","epoch 20, loss 0.0007, train acc 0.939, test acc 0.902, time 11.1 sec\n","epoch 21, loss 0.0007, train acc 0.940, test acc 0.902, time 11.0 sec\n","epoch 22, loss 0.0007, train acc 0.941, test acc 0.903, time 11.0 sec\n","epoch 23, loss 0.0006, train acc 0.943, test acc 0.902, time 10.2 sec\n","epoch 24, loss 0.0006, train acc 0.944, test acc 0.901, time 10.9 sec\n","epoch 25, loss 0.0006, train acc 0.946, test acc 0.902, time 11.0 sec\n","epoch 26, loss 0.0006, train acc 0.947, test acc 0.902, time 11.0 sec\n","epoch 27, loss 0.0006, train acc 0.948, test acc 0.902, time 11.2 sec\n","epoch 28, loss 0.0006, train acc 0.950, test acc 0.903, time 10.4 sec\n","epoch 29, loss 0.0006, train acc 0.951, test acc 0.903, time 11.0 sec\n","epoch 30, loss 0.0006, train acc 0.952, test acc 0.902, time 11.0 sec\n","epoch 31, loss 0.0005, train acc 0.953, test acc 0.902, time 11.1 sec\n","epoch 32, loss 0.0005, train acc 0.955, test acc 0.901, time 11.2 sec\n","epoch 33, loss 0.0005, train acc 0.956, test acc 0.901, time 10.7 sec\n","epoch 34, loss 0.0005, train acc 0.957, test acc 0.901, time 10.7 sec\n","epoch 35, loss 0.0005, train acc 0.958, test acc 0.901, time 11.0 sec\n","epoch 36, loss 0.0005, train acc 0.959, test acc 0.900, time 11.0 sec\n","epoch 37, loss 0.0005, train acc 0.960, test acc 0.900, time 11.1 sec\n","epoch 38, loss 0.0005, train acc 0.961, test acc 0.899, time 11.0 sec\n","epoch 39, loss 0.0005, train acc 0.962, test acc 0.899, time 10.5 sec\n","epoch 40, loss 0.0005, train acc 0.963, test acc 0.899, time 11.0 sec\n","epoch 41, loss 0.0004, train acc 0.964, test acc 0.899, time 11.0 sec\n","epoch 42, loss 0.0004, train acc 0.965, test acc 0.899, time 11.1 sec\n","epoch 43, loss 0.0004, train acc 0.965, test acc 0.898, time 11.2 sec\n","epoch 44, loss 0.0004, train acc 0.966, test acc 0.898, time 10.6 sec\n","epoch 45, loss 0.0004, train acc 0.967, test acc 0.898, time 11.0 sec\n","epoch 46, loss 0.0004, train acc 0.968, test acc 0.898, time 11.0 sec\n","epoch 47, loss 0.0004, train acc 0.969, test acc 0.898, time 11.1 sec\n","epoch 48, loss 0.0004, train acc 0.969, test acc 0.899, time 11.2 sec\n","epoch 49, loss 0.0004, train acc 0.970, test acc 0.898, time 10.8 sec\n","epoch 50, loss 0.0004, train acc 0.971, test acc 0.899, time 10.7 sec\n","CPU times: user 9min 1s, sys: 1.72 s, total: 9min 3s\n","Wall time: 9min 5s\n"]}],"source":["%%time\n","loss = torch.nn.CrossEntropyLoss() # функция потерь для классификации\n","lr, num_epochs = 0.01, 50\n","trainer = torch.optim.SGD(model5.parameters(), lr=lr)\n","train_device(model5, train, test, trainer, num_epochs, device)"]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Для новой архитектуры с 4 сверточными слоями обучение до\n","<br>\n","train_acc: 0.883, test_acc: 0.875\n","<br>\n","наступает на 3 эпохе.\n","<br>\n","обучение до зачетного уровня\n","<br>\n","train acc 0.915, test acc 0.895\n","<br>\n","наступает на 9 эпохе.\n","<br>\n","а с 12 эпохи наступает переобучение\n","<br>\n","На расчет 10 эпох на GPU уходит 2 минуты.\n","<br>\n","<br>\n","Если полносвязные слои - это \"прокачанная\" апроксимация первого порядка из мира традиционной науки, то сверточные методы это первая ласточка понастоящему нейронных подходов, делающих шаг в сторону от проторенной дорожки традиций и привычек.\n","</font>"],"metadata":{"id":"qn5Gr-AwH3oo"}},{"cell_type":"markdown","source":["\n","|Архитектура|эпоха|train acc|test acc|\n","|:------------------------|:---|:-------|:--------|\n","|полносвязный вариант|10|0.80975|0.7988|\n","|комбинированный вариант с 2 сверточными слоями|10|0.71612|0.7266|\n","|комбинированный вариант с 2 сверточными слоями|20|0.800|0.797|\n","|комбинированный вариант с 3 сверточными слоями|10|0.719|0.693|\n","|комбинированный с 3 сверточными слоями и 1 нормализацией|10|0.881|0.873|\n","|комбинированный с 3 сверточными слоями c 3 нормализациями|6|0.882|0.873|\n","|комбинированный с 3 сверточными слоями c 3 нормализациями|10|0.896|0.879|\n","|комбинированный с 3 сверточными слоями c 4 нормализациями|3|0.883|0.875|\n","|комбинированный с 3 сверточными слоями c 4 нормализациями|9|0.915|0.895|\n","|комбинированный с 3 сверточными слоями c 4 нормализациями|10|0.918|0.896|\n","|||||\n","|||||\n","<font color=green size=3>\n","<br>\n","</font>"],"metadata":{"id":"DYwuIRSPSn3W"}},{"cell_type":"code","source":[],"metadata":{"id":"pPJzlw4WaNqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8hsdJtW4zhAQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color=green size=3>\n","Это шаблон примечания\n","<br>\n","<br>\n","</font>"],"metadata":{"id":"Bh6nSH0dAjWq"}},{"cell_type":"markdown","source":["первая строка  \n","вторая строка  \n","два пробела и ентер  \n"],"metadata":{"id":"rKu_xHisAMr8"}}]}