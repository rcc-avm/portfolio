{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1W8I0rbhYPeULVR9IK0UBxNp76NvoumjW","timestamp":1707307885767}],"mount_file_id":"1W8I0rbhYPeULVR9IK0UBxNp76NvoumjW","authorship_tag":"ABX9TyMRwoTFzmjxxVVw0jWflKO2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Задание 1.\n","Обучите нейронную сеть решать шифр Цезаря.  \n","  \n","Что необходимо сделать:  \n","\n","\n","Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)  \n","\n","Сделать нейронную сеть  \n","\n","Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)  \n","\n","Проверить качество"],"metadata":{"id":"ZdX0YMexFnO7"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSdfL3LpNGz_","executionInfo":{"status":"ok","timestamp":1708084840735,"user_tz":-180,"elapsed":2530,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"bd9206ee-8f72-4bfa-d9ae-59ac1f89c77f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Задание 2.\n","Выполнить практическую работу из лекционного ноутбука.\n","\n","Построить RNN-ячейку на основе полносвязных слоев  \n","\n","Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”\n","\n","PyTorch RNN from Scratch  \n","  \n","  https://jaketae.github.io/study/pytorch-rnn/"],"metadata":{"id":"BCpLnV_VNHsh"}},{"cell_type":"code","source":[],"metadata":{"id":"_JjKYxsTFo14"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Rq-LP3YuI2w"},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import time\n","import random\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQj87CmZ-SJ0"},"outputs":[],"source":["import inspect\n","import pickle\n","import os\n","import sys\n","base_dir = '/content/drive/MyDrive/tmp/'\n","def sizeof_fmt(num, suffix='B'):\n","    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n","    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n","        if abs(num) < 1024.0:\n","            return \"%3.1f %s%s\" % (num, unit, suffix)\n","        num /= 1024.0\n","    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n","\n","def show_memory_usage(objs=locals().items()):\n","    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in objs), key=lambda x: -x[1])[:10]:\n","        if name[0] != '_' and name not in ['rcParams', 'rcParamsDefault', 'rcParamsOrig', 'sctypeNA']:\n","            print(f\"{name:>30}: {sizeof_fmt(size):>8}\")\n","\n","def save_pickle(obj, fname, dir=base_dir):\n","    full_fname = dir + '/' + fname\n","    with open(full_fname, 'wb') as pickle_file:\n","        pickle.dump(obj, pickle_file)\n","    print(f\"saved \\\"{fname}\\\" ({sizeof_fmt(os.path.getsize(full_fname))}).\")\n","\n","def load_pickle(fname, dir=base_dir):\n","    full_fname = dir + '/' + fname\n","    with open(full_fname, 'rb') as pickle_file:\n","        obj = pickle.load(pickle_file)\n","    print(f\"loaded \\\"{fname}\\\" ({sizeof_fmt(os.path.getsize(full_fname))}).\")\n","    return obj"]},{"cell_type":"markdown","source":["Saving & Loading Model for Inference\n","Save/Load state_dict (Recommended)\n","\n","Save:\n","\n","torch.save(model.state_dict(), PATH)\n","\n","Load:\n","\n","model = TheModelClass(*args, **kwargs)\n","model.load_state_dict(torch.load(PATH))\n","model.eval()\n"],"metadata":{"id":"Jw5CkNNTqBo5"}},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/data/data.csv') # скачаем реплики Симпсонов\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"ngXKojDG715i","executionInfo":{"status":"ok","timestamp":1708084840738,"user_tz":-180,"elapsed":28,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"1ae00ed3-48c1-4d9e-c603-83691fe78ec8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0     id  episode_id  number  \\\n","0           0  10368          35      29   \n","1           1  10369          35      30   \n","2           2  10370          35      31   \n","3           3  10372          35      33   \n","4           4  10374          35      35   \n","\n","                                            raw_text  timestamp_in_ms  \\\n","0           Lisa Simpson: Maggie, look. What's that?           235000   \n","1                    Lisa Simpson: Lee-mur. Lee-mur.           237000   \n","2                    Lisa Simpson: Zee-boo. Zee-boo.           239000   \n","3  Lisa Simpson: I'm trying to teach Maggie that ...           245000   \n","4  Lisa Simpson: It's like an ox, only it has a h...           254000   \n","\n","   speaking_line  character_id  location_id raw_character_text  \\\n","0           True             9          5.0       Lisa Simpson   \n","1           True             9          5.0       Lisa Simpson   \n","2           True             9          5.0       Lisa Simpson   \n","3           True             9          5.0       Lisa Simpson   \n","4           True             9          5.0       Lisa Simpson   \n","\n","  raw_location_text                                       spoken_words  \\\n","0      Simpson Home                         Maggie, look. What's that?   \n","1      Simpson Home                                  Lee-mur. Lee-mur.   \n","2      Simpson Home                                  Zee-boo. Zee-boo.   \n","3      Simpson Home  I'm trying to teach Maggie that nature doesn't...   \n","4      Simpson Home  It's like an ox, only it has a hump and a dewl...   \n","\n","                                     normalized_text  word_count  \n","0                             maggie look whats that         4.0  \n","1                                    lee-mur lee-mur         2.0  \n","2                                    zee-boo zee-boo         2.0  \n","3  im trying to teach maggie that nature doesnt e...        24.0  \n","4  its like an ox only it has a hump and a dewlap...        18.0  "],"text/html":["\n","  <div id=\"df-76715fd8-3a35-4cfb-a56f-7130c8de63bb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>episode_id</th>\n","      <th>number</th>\n","      <th>raw_text</th>\n","      <th>timestamp_in_ms</th>\n","      <th>speaking_line</th>\n","      <th>character_id</th>\n","      <th>location_id</th>\n","      <th>raw_character_text</th>\n","      <th>raw_location_text</th>\n","      <th>spoken_words</th>\n","      <th>normalized_text</th>\n","      <th>word_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>10368</td>\n","      <td>35</td>\n","      <td>29</td>\n","      <td>Lisa Simpson: Maggie, look. What's that?</td>\n","      <td>235000</td>\n","      <td>True</td>\n","      <td>9</td>\n","      <td>5.0</td>\n","      <td>Lisa Simpson</td>\n","      <td>Simpson Home</td>\n","      <td>Maggie, look. What's that?</td>\n","      <td>maggie look whats that</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>10369</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>Lisa Simpson: Lee-mur. Lee-mur.</td>\n","      <td>237000</td>\n","      <td>True</td>\n","      <td>9</td>\n","      <td>5.0</td>\n","      <td>Lisa Simpson</td>\n","      <td>Simpson Home</td>\n","      <td>Lee-mur. Lee-mur.</td>\n","      <td>lee-mur lee-mur</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>10370</td>\n","      <td>35</td>\n","      <td>31</td>\n","      <td>Lisa Simpson: Zee-boo. Zee-boo.</td>\n","      <td>239000</td>\n","      <td>True</td>\n","      <td>9</td>\n","      <td>5.0</td>\n","      <td>Lisa Simpson</td>\n","      <td>Simpson Home</td>\n","      <td>Zee-boo. Zee-boo.</td>\n","      <td>zee-boo zee-boo</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>10372</td>\n","      <td>35</td>\n","      <td>33</td>\n","      <td>Lisa Simpson: I'm trying to teach Maggie that ...</td>\n","      <td>245000</td>\n","      <td>True</td>\n","      <td>9</td>\n","      <td>5.0</td>\n","      <td>Lisa Simpson</td>\n","      <td>Simpson Home</td>\n","      <td>I'm trying to teach Maggie that nature doesn't...</td>\n","      <td>im trying to teach maggie that nature doesnt e...</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>10374</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>Lisa Simpson: It's like an ox, only it has a h...</td>\n","      <td>254000</td>\n","      <td>True</td>\n","      <td>9</td>\n","      <td>5.0</td>\n","      <td>Lisa Simpson</td>\n","      <td>Simpson Home</td>\n","      <td>It's like an ox, only it has a hump and a dewl...</td>\n","      <td>its like an ox only it has a hump and a dewlap...</td>\n","      <td>18.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76715fd8-3a35-4cfb-a56f-7130c8de63bb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-76715fd8-3a35-4cfb-a56f-7130c8de63bb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-76715fd8-3a35-4cfb-a56f-7130c8de63bb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ce8f4a9b-25f6-46df-942e-6919651ed83b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce8f4a9b-25f6-46df-942e-6919651ed83b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ce8f4a9b-25f6-46df-942e-6919651ed83b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11639,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3360,\n        \"min\": 0,\n        \"max\": 11638,\n        \"samples\": [\n          11589,\n          850,\n          9614\n        ],\n        \"num_unique_values\": 11639,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44687,\n        \"min\": 36,\n        \"max\": 158250,\n        \"samples\": [\n          9585,\n          30730,\n          152521\n        ],\n        \"num_unique_values\": 11639,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159,\n        \"min\": 1,\n        \"max\": 568,\n        \"samples\": [\n          528,\n          497,\n          448\n        ],\n        \"num_unique_values\": 562,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84,\n        \"min\": 0,\n        \"max\": 390,\n        \"samples\": [\n          254,\n          34,\n          1\n        ],\n        \"num_unique_values\": 363,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Lisa Simpson: Mom, Dad! Mr. Burns is a vampire, and he has Bart!\",\n          \"Lisa Simpson: No, we should fix things here. If we put our minds to it, there's no limit to what we can accomplish.\",\n          \"Lisa Simpson: Dad, you were supposed to read me a bedtime story.\"\n        ],\n        \"num_unique_values\": 10850,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_in_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 358854,\n        \"min\": 0,\n        \"max\": 1379000,\n        \"samples\": [\n          557000,\n          95000,\n          1168000\n        ],\n        \"num_unique_values\": 1310,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaking_line\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"samples\": [\n          false,\n          true\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"character_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 9,\n        \"max\": 9,\n        \"samples\": [\n          9\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1188.8990637615846,\n        \"min\": 1.0,\n        \"max\": 4447.0,\n        \"samples\": [\n          772.0\n        ],\n        \"num_unique_values\": 1280,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_character_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Lisa's Thoughts\"\n        ],\n        \"num_unique_values\": 4,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_location_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"BEER HALL OF THE PRESIDENTS\"\n        ],\n        \"num_unique_values\": 1283,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spoken_words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"I have an issue I'd like to raise!\"\n        ],\n        \"num_unique_values\": 10277,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"i thought you rowed up the zambezi without a guide\"\n        ],\n        \"num_unique_values\": 10136,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.437453585119546,\n        \"min\": 0.0,\n        \"max\": 75.0,\n        \"samples\": [\n          52.0\n        ],\n        \"num_unique_values\": 64,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AmSYnoc8O5U","executionInfo":{"status":"ok","timestamp":1708084840738,"user_tz":-180,"elapsed":24,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"882b180d-d738-43c7-ea27-e96c5e12ec43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 11639 entries, 0 to 11638\n","Data columns (total 14 columns):\n"," #   Column              Non-Null Count  Dtype  \n","---  ------              --------------  -----  \n"," 0   Unnamed: 0          11639 non-null  int64  \n"," 1   id                  11639 non-null  int64  \n"," 2   episode_id          11639 non-null  int64  \n"," 3   number              11639 non-null  int64  \n"," 4   raw_text            11639 non-null  object \n"," 5   timestamp_in_ms     11639 non-null  int64  \n"," 6   speaking_line       11639 non-null  bool   \n"," 7   character_id        11639 non-null  int64  \n"," 8   location_id         11622 non-null  float64\n"," 9   raw_character_text  11639 non-null  object \n"," 10  raw_location_text   11622 non-null  object \n"," 11  spoken_words        10893 non-null  object \n"," 12  normalized_text     10891 non-null  object \n"," 13  word_count          10893 non-null  float64\n","dtypes: bool(1), float64(2), int64(6), object(5)\n","memory usage: 1.2+ MB\n"]}]},{"cell_type":"markdown","source":["Возьмем из датасета уже нормализованный текст и выберем из него нормальные фразы длиннее 10 символов и без NaN значений."],"metadata":{"id":"VJDzbtrlrWNF"}},{"cell_type":"code","source":["inputs = df.loc[df['normalized_text']. str.len () > 10 ]['normalized_text'].dropna().to_list() # оставим реплики больше 10 символов\n","inputs[-5:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3o2yCo-l8oSJ","executionInfo":{"status":"ok","timestamp":1708084840739,"user_tz":-180,"elapsed":20,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"fdad0a34-2fc6-4bb8-c034-33253a78ff5c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['too bad we didnt come dressed as popular cartoon characters',\n"," 'yeah mom guess what for a dollar a man sold me thirty-five caspers and a dozen lois lanes',\n"," 'hows it going bart',\n"," 'maybe you need to play on their sympathies more lets see',\n"," 'ah ha now you look pathetic']"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","source":["Напишем функцию для кодирования по коду Цезаря."],"metadata":{"id":"gjo6ZU4ysHa2"}},{"cell_type":"code","source":["def cod_Сaesar(string, num):\n","    output = ''\n","    for c in string:\n","        if c.isalpha():\n","            new_num = ord(c) + num\n","            if new_num > ord('z'):\n","                new_num -= 26\n","            output += chr(new_num)\n","        else:\n","            output += c\n","    return output"],"metadata":{"id":"DVSlWvo4ATfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cod_Сaesar('abc3yz',2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HgrX53k2Ah-M","executionInfo":{"status":"ok","timestamp":1708084840740,"user_tz":-180,"elapsed":17,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"f74a1cfb-7c4f-43a1-a932-c43a735c5c6a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cde3ab'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["def do_dataset(inputs):\n","  outputs = []\n","  shift = []\n","  for str in inputs:\n","    n = random.randint(1, 10)\n","    shift.append(n)\n","    outputs.append(cod_Сaesar([i for i in str],n))\n","  return outputs, shift\n"],"metadata":{"id":"OlA-D8jICn-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs, shift = do_dataset(inputs)\n","len(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Jb7kZ5DCoIm","executionInfo":{"status":"ok","timestamp":1708084841209,"user_tz":-180,"elapsed":483,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"56d41e74-90f2-47f1-c199-b5750907c6d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9507"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["Применили кодирование. Получили по 9507 исходных и  кодированных образцов."],"metadata":{"id":"pnEl7_RZsYsb"}},{"cell_type":"code","source":["inputs[-5:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KeGa7mDHUQb","executionInfo":{"status":"ok","timestamp":1708084841209,"user_tz":-180,"elapsed":18,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"78103c4e-db82-470a-9beb-d55beea92b2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['too bad we didnt come dressed as popular cartoon characters',\n"," 'yeah mom guess what for a dollar a man sold me thirty-five caspers and a dozen lois lanes',\n"," 'hows it going bart',\n"," 'maybe you need to play on their sympathies more lets see',\n"," 'ah ha now you look pathetic']"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["outputs[-5:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qj0FZAcNdoPD","executionInfo":{"status":"ok","timestamp":1708084841210,"user_tz":-180,"elapsed":15,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"02f0e7b8-265a-465e-b359-37fe0bdcb2d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['dyy lkn go nsnxd mywo nboccon kc zyzevkb mkbdyyx mrkbkmdobc',\n"," 'ciel qsq kyiww alex jsv e hsppev e qer wsph qi xlmvxc-jmzi gewtivw erh e hsdir psmw periw',\n"," 'mtbx ny ltnsl gfwy',\n"," 'rfdgj dtz sjji yt uqfd ts ymjnw xdrufymnjx rtwj qjyx xjj',\n"," 'ip pi vwe gwc twws xibpmbqk']"]},"metadata":{},"execution_count":74}]},{"cell_type":"markdown","source":["Разделим их на тренировочный и тестовый наборы в пропорции 80/20 и переместим в структуры pytorch."],"metadata":{"id":"8GOvulE2stSP"}},{"cell_type":"code","source":["train_text, test_text, train_label, test_label = train_test_split(outputs, inputs, test_size=0.2)"],"metadata":{"id":"EOd_e7cmkOJw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_text[1], train_label[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S41nO5ARkPtG","executionInfo":{"status":"ok","timestamp":1708084841210,"user_tz":-180,"elapsed":10,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"49475e05-e04a-4a79-adba-5dfda0da2f82"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('xliczi xeoir izivcxlmrk', 'theyve taken everything')"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["DICT_           = ['none'] + [w for w in set('abcdefghijklmnopqrstuvwxyz ')] # еще раз закодируем, теперь уже цифрами по словарю.\n","CHAR_TO_INDEX = {w: i for i, w in enumerate(DICT_)}\n","INDEX_TO_CHAR = {i: w for i, w in enumerate(DICT_)}\n","MAX_LEN = 70 # ограничим фразы 70 символами\n","\n","def convert_to_torch(text):\n","    output = torch.zeros((len(text), MAX_LEN), dtype=int)\n","    for i in range(len(text)):\n","        for j, w in enumerate(text[i]):\n","            if j >= MAX_LEN:\n","                break\n","            output[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])\n","\n","    return output"],"metadata":{"id":"64q6gB2wk9bv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = convert_to_torch(train_text)\n","X_test = convert_to_torch(test_text)\n","y_train = convert_to_torch(train_label)\n","y_test = convert_to_torch(test_label)"],"metadata":{"id":"Zw4hpIeemmqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[1], y_train[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc8meJVMnQ3g","executionInfo":{"status":"ok","timestamp":1708084848991,"user_tz":-180,"elapsed":36,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"102db5b1-9aa7-40ad-e36e-4f113b313f57"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([11,  4,  6,  3, 13,  6, 16, 11, 19, 12,  6, 22, 16,  6, 13,  6, 26,  3,\n","         11,  4, 18, 22, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n"," tensor([25, 10, 19, 15, 26, 19, 16, 25,  9, 24, 19, 23, 16, 19, 26, 19, 22, 15,\n","         25, 10,  6, 23,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]))"]},"metadata":{},"execution_count":79}]},{"cell_type":"markdown","source":["На глаз порядок наблюдается только в пробелах и длине фраз."],"metadata":{"id":"8qzPiVjYuOqh"}},{"cell_type":"markdown","source":["Теперь создадим нашу рекурентную сеть."],"metadata":{"id":"3irS6KZQukRA"}},{"cell_type":"code","metadata":{"id":"hLDPN3VXJsLJ"},"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zm2UTy-eavqU"},"source":["class RNN_net(torch.nn.Module):\n","    def __init__(self):\n","        super(RNN_net, self).__init__()\n","        self.embeddings = torch.nn.Embedding(len(DICT_), 28) # определим длину вектора ембеддингов в 28\n","        self.rnn = torch.nn.RNN(28, 256, batch_first=True) # назначим скрытое сосотояние в 256\n","        self.linear = torch.nn.Linear(256, 28) # здесь 28 - это классификация на 28 символов\n","\n","    def forward(self, sentences, state=None):\n","        embds = self.embeddings(sentences)\n","        out, new_state = self.rnn(embds, state)\n","        result = self.linear(out)\n","        return result, new_state"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8zf6Spu8kxd"},"source":["model = RNN_net().to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","epochs    = 40\n","loss_best = 10**10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdSOS6x7WEFD","outputId":"10a0414d-686a-4fbe-bf9e-8601f45463ef","executionInfo":{"status":"ok","timestamp":1708086083694,"user_tz":-180,"elapsed":1234733,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}}},"source":["%%time\n","for epoch in range(epochs):\n","    start = time.time()\n","    train_loss = 0\n","    train_passed = 0\n","    test_loss = 0\n","    test_passed = 0\n","\n","    for i in range(int(len(X_train) / 100)):\n","        X_batch = X_train[i * 100:(i + 1) * 100].to(device)\n","        y_batch = y_train[i * 100:(i + 1) * 100].flatten().to(device)\n","        model.train()\n","        optimizer.zero_grad()\n","        answers, _ = model.forward(X_batch)\n","        answers = answers.view(-1, len(DICT_))\n","        loss = criterion(answers, y_batch).to(device)\n","\n","        if loss < loss_best:\n","            model_best = copy.copy(model) # сохраняем состояние модели с наименьшей ошибкой\n","            loss_best = loss\n","\n","        train_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        train_passed += 1\n","\n","    with torch.no_grad():\n","        model.eval()\n","        answers, _ = model.forward(X_test.to(device))\n","        answers = answers.view(-1, len(DICT_))\n","        loss = criterion(answers, y_test.flatten().to(device))\n","        test_loss += loss.item()\n","        test_passed += 1\n","\n","    if epoch%1 == 0:\n","        print(f\"Epoch {epoch}. Time: {time.time() - start:.3f}, Train loss: {train_loss / train_passed:.3f}, Test loss: {test_loss / test_passed:.6f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0. Time: 30.694, Train loss: 1.813, Test loss: 1.403555\n","Epoch 1. Time: 30.704, Train loss: 1.278, Test loss: 1.155535\n","Epoch 2. Time: 32.039, Train loss: 1.081, Test loss: 1.021335\n","Epoch 3. Time: 32.355, Train loss: 0.991, Test loss: 0.964004\n","Epoch 4. Time: 30.666, Train loss: 0.949, Test loss: 0.932568\n","Epoch 5. Time: 31.977, Train loss: 0.923, Test loss: 0.910797\n","Epoch 6. Time: 30.794, Train loss: 0.903, Test loss: 0.892525\n","Epoch 7. Time: 31.114, Train loss: 0.884, Test loss: 0.871349\n","Epoch 8. Time: 30.824, Train loss: 0.856, Test loss: 0.833155\n","Epoch 9. Time: 33.975, Train loss: 0.813, Test loss: 0.786719\n","Epoch 10. Time: 30.531, Train loss: 0.755, Test loss: 0.718553\n","Epoch 11. Time: 30.986, Train loss: 0.692, Test loss: 0.671702\n","Epoch 12. Time: 31.384, Train loss: 0.634, Test loss: 0.597141\n","Epoch 13. Time: 30.256, Train loss: 0.580, Test loss: 0.549636\n","Epoch 14. Time: 30.508, Train loss: 0.549, Test loss: 0.508574\n","Epoch 15. Time: 31.427, Train loss: 0.489, Test loss: 0.466139\n","Epoch 16. Time: 31.363, Train loss: 0.457, Test loss: 0.438002\n","Epoch 17. Time: 30.237, Train loss: 0.418, Test loss: 0.406186\n","Epoch 18. Time: 30.334, Train loss: 0.390, Test loss: 0.393188\n","Epoch 19. Time: 30.088, Train loss: 0.361, Test loss: 0.355070\n","Epoch 20. Time: 33.184, Train loss: 0.334, Test loss: 0.357578\n","Epoch 21. Time: 30.156, Train loss: 0.343, Test loss: 0.361649\n","Epoch 22. Time: 30.024, Train loss: 0.307, Test loss: 0.301544\n","Epoch 23. Time: 30.092, Train loss: 0.272, Test loss: 0.280007\n","Epoch 24. Time: 31.307, Train loss: 0.249, Test loss: 0.262140\n","Epoch 25. Time: 30.064, Train loss: 0.232, Test loss: 0.245972\n","Epoch 26. Time: 31.561, Train loss: 0.216, Test loss: 0.233941\n","Epoch 27. Time: 29.972, Train loss: 0.203, Test loss: 0.228472\n","Epoch 28. Time: 31.386, Train loss: 0.201, Test loss: 0.223329\n","Epoch 29. Time: 30.197, Train loss: 0.194, Test loss: 0.205332\n","Epoch 30. Time: 29.662, Train loss: 0.170, Test loss: 0.202098\n","Epoch 31. Time: 29.885, Train loss: 0.163, Test loss: 0.209536\n","Epoch 32. Time: 32.486, Train loss: 0.153, Test loss: 0.181879\n","Epoch 33. Time: 29.943, Train loss: 0.143, Test loss: 0.175827\n","Epoch 34. Time: 29.741, Train loss: 0.155, Test loss: 0.292404\n","Epoch 35. Time: 29.699, Train loss: 0.190, Test loss: 0.175581\n","Epoch 36. Time: 29.736, Train loss: 0.162, Test loss: 0.172705\n","Epoch 37. Time: 31.185, Train loss: 0.130, Test loss: 0.160345\n","Epoch 38. Time: 31.528, Train loss: 0.120, Test loss: 0.159365\n","Epoch 39. Time: 30.523, Train loss: 0.116, Test loss: 0.158306\n","CPU times: user 19min 16s, sys: 1min 10s, total: 20min 26s\n","Wall time: 20min 34s\n"]}]},{"cell_type":"markdown","source":["Выводим наименьшую ошибку."],"metadata":{"id":"CM0ChfVgdYIt"}},{"cell_type":"code","source":["loss_best"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-5Ipz9A2dOL","executionInfo":{"status":"ok","timestamp":1708086083694,"user_tz":-180,"elapsed":63,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"ea73b602-bcef-492b-8ee9-44b883e79df9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0945, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["to_decode = X_train[0]\n","to_decode"],"metadata":{"id":"N0V0c_BQ2w_f","executionInfo":{"status":"ok","timestamp":1708086083696,"user_tz":-180,"elapsed":26,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"73a94435-a4a3-478a-be0a-d696af8f4483"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([17, 12, 10,  9, 16, 10,  6, 26, 21,  9, 16,  6, 10, 15,  9, 13, 16,  6,\n","         4, 24, 15, 26, 26, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["res = model_best(to_decode.to(device))"],"metadata":{"id":"EXAe5Wg2WeRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CazNylVtjB0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWQFSIxFXuFZ","executionInfo":{"status":"ok","timestamp":1708086083698,"user_tz":-180,"elapsed":21,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"f06e1cf1-68c6-4b8b-b7ed-4eef3ea9f8eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([70, 28])"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["result = ''.join([INDEX_TO_CHAR[i.item()] for i\n","                    in res[0].argmax(dim=1).detach()])\n","# res.topk(1) вместо res[0].argmax(dim=1).detach() ?\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"0esaT6eydu7a","executionInfo":{"status":"ok","timestamp":1708086083698,"user_tz":-180,"elapsed":17,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"89f64205-f012-4cdf-c887-b29044ee30f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'what about barts bedroomnonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["Раскодировали первую строку тренировочного набора.  \n","\n","  \n","Посмотрим, что получится, если возьмем 507 любых записей с конца отобранного массива.\n"],"metadata":{"id":"15dQxg2-d8PL"}},{"cell_type":"code","source":["outputs_torch_507 = convert_to_torch(outputs[9000:])"],"metadata":{"id":"3CUfOlaXXewe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs_torch_507.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PakY3lLFYEBa","executionInfo":{"status":"ok","timestamp":1708086084105,"user_tz":-180,"elapsed":11,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"8f653707-0ad4-418f-ae90-ecfb9b24af7b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([507, 70])"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["predicts_507 = [''.join([INDEX_TO_CHAR[i.item()] for i\n","                    in model_best(outputs_torch_507.to(device))[0][line].argmax(dim=1).detach()])\n","                    for line in range(506)]\n","                    # outputs_torch_507.topk(1) вместо outputs_torch_507[0].argmax(dim=1).detach() ?\n","predicts_507[500:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708086253794,"user_tz":-180,"elapsed":169694,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"8085b460-1d58-4b48-b8cd-f41128617722","id":"5sA-qF1DXewz"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ies no wittier than the neyt superherononenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone',\n"," 'i stand correctednonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone',\n"," 'wor bad we didnt come dressed as popular cartoon charactersnonenonenonenonenonenonenonenonenonenonenone',\n"," 'weah mom guess what for a dollar a man sold me thirtynonefive caspers and',\n"," 'iowr it going bartnonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenonenone',\n"," 'iaade you need to play on their sympathies more lets seenonenonenonenonenonenonenonenonenonenonenonenonenonenone']"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["clm = ['predicts', 'shift', 'inputs', 'outputs']\n","df_res = pd.DataFrame(list(zip(predicts_507, shift[9000:], inputs[9000:], outputs[9000:])), columns=clm)\n","df_res.head(20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"clXZviMokiIh","executionInfo":{"status":"ok","timestamp":1708086253794,"user_tz":-180,"elapsed":81,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b6d55aa1-6c47-4f63-ec6c-92987d10e6fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             predicts  shift  \\\n","0   de now for a little powder bluenonenonenonenon...      7   \n","1   ih no ie wouldntnonenonenonenonenonenonenoneno...      4   \n","2   wad how could you we were connecting in such a...      2   \n","3   iey whats thisnonenonenonenonenonenonenonenone...      9   \n","4   iesw im taking the cowards way out but before ...      3   \n","5   im gonna wear my apron on the fourth of julyno...      6   \n","6   whey are coming back for us arent theynonenone...      8   \n","7   iowu your back dadnonenonenonenonenonenonenone...      7   \n","8   wart tuit it bart uuit it uuit it uuit itnonen...      5   \n","9   wheyre all around me no way out no way out i t...      5   \n","10  whae i can ree the musicnonenonenonenonenoneno...      1   \n","11  i am the lidard uueennonenonenonenonenonenonen...      5   \n","12  want talk comin downnonenonenonenonenonenoneno...      1   \n","13  taat you be forever dialing that phonenonenone...      9   \n","14  oh doon hurtynonenonenonenonenonenonenonenonen...      5   \n","15  ih no its a package from ralphnonenonenonenone...      4   \n","16  irnt that just pointless busyworknonenonenonen...      7   \n","17  iere you go ralphnonenonenonenonenonenonenonen...      2   \n","18  iarow ualentinesnonenonenonenonenonenonenoneno...      3   \n","19  wtye i guessnonenonenonenonenonenonenonenoneno...      8   \n","\n","                                               inputs  \\\n","0                     ah now for a little powder blue   \n","1                                    oh no he wouldnt   \n","2   dad how could you we were connecting in such a...   \n","3                                      hey whats this   \n","4   lisa im taking the cowards way out but before ...   \n","5        im gonna wear my apron on the fourth of july   \n","6              they are coming back for us arent they   \n","7                                  hows your back dad   \n","8           bart quit it bart quit it quit it quit it   \n","9   theyre all around me no way out no way out i t...   \n","10                           ahhh i can see the music   \n","11                              i am the lizard queen   \n","12                               cant talk comin down   \n","13             must you be forever dialing that phone   \n","14                                      oh cmon hurry   \n","15                     oh no its a package from ralph   \n","16                  isnt that just pointless busywork   \n","17                                  here you go ralph   \n","18                                   happy valentines   \n","19                                       sure i guess   \n","\n","                                              outputs  \n","0                     ho uvd mvy h spaasl wvdkly isbl  \n","1                                    sl rs li asyphrx  \n","2   fcf jqy eqwnf aqw yg ygtg eqppgevkpi kp uwej c...  \n","3                                      qnh fqjcb cqrb  \n","4   olvd lp wdnlqj wkh frzdugv zdb rxw exw ehiruh ...  \n","5        os muttg ckgx se gvxut ut znk luaxzn ul pare  \n","6              bpmg izm kwuqvo jiks nwz ca izmvb bpmg  \n","7                                  ovdz fvby ihjr khk  \n","8           gfwy vzny ny gfwy vzny ny vzny ny vzny ny  \n","9   ymjdwj fqq fwtzsi rj st bfd tzy st bfd tzy n y...  \n","10                           biii j dbo tff uif nvtjd  \n","11                              n fr ymj qnefwi vzjjs  \n","12                               dbou ubml dpnjo epxo  \n","13             vdbc hxd kn oxanena mrjurwp cqjc yqxwn  \n","14                                      tm hrts mzwwd  \n","15                     sl rs mxw e tegoeki jvsq veptl  \n","16                  pzua aoha qbza wvpuaslzz ibzfdvyr  \n","17                                  jgtg aqw iq tcnrj  \n","18                                   kdssb ydohqwlqhv  \n","19                                       aczm q ocmaa  "],"text/html":["\n","  <div id=\"df-1f79baad-6edf-4844-a6cd-a97973161369\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>predicts</th>\n","      <th>shift</th>\n","      <th>inputs</th>\n","      <th>outputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>de now for a little powder bluenonenonenonenon...</td>\n","      <td>7</td>\n","      <td>ah now for a little powder blue</td>\n","      <td>ho uvd mvy h spaasl wvdkly isbl</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ih no ie wouldntnonenonenonenonenonenonenoneno...</td>\n","      <td>4</td>\n","      <td>oh no he wouldnt</td>\n","      <td>sl rs li asyphrx</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wad how could you we were connecting in such a...</td>\n","      <td>2</td>\n","      <td>dad how could you we were connecting in such a...</td>\n","      <td>fcf jqy eqwnf aqw yg ygtg eqppgevkpi kp uwej c...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>iey whats thisnonenonenonenonenonenonenonenone...</td>\n","      <td>9</td>\n","      <td>hey whats this</td>\n","      <td>qnh fqjcb cqrb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>iesw im taking the cowards way out but before ...</td>\n","      <td>3</td>\n","      <td>lisa im taking the cowards way out but before ...</td>\n","      <td>olvd lp wdnlqj wkh frzdugv zdb rxw exw ehiruh ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>im gonna wear my apron on the fourth of julyno...</td>\n","      <td>6</td>\n","      <td>im gonna wear my apron on the fourth of july</td>\n","      <td>os muttg ckgx se gvxut ut znk luaxzn ul pare</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>whey are coming back for us arent theynonenone...</td>\n","      <td>8</td>\n","      <td>they are coming back for us arent they</td>\n","      <td>bpmg izm kwuqvo jiks nwz ca izmvb bpmg</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>iowu your back dadnonenonenonenonenonenonenone...</td>\n","      <td>7</td>\n","      <td>hows your back dad</td>\n","      <td>ovdz fvby ihjr khk</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>wart tuit it bart uuit it uuit it uuit itnonen...</td>\n","      <td>5</td>\n","      <td>bart quit it bart quit it quit it quit it</td>\n","      <td>gfwy vzny ny gfwy vzny ny vzny ny vzny ny</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>wheyre all around me no way out no way out i t...</td>\n","      <td>5</td>\n","      <td>theyre all around me no way out no way out i t...</td>\n","      <td>ymjdwj fqq fwtzsi rj st bfd tzy st bfd tzy n y...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>whae i can ree the musicnonenonenonenonenoneno...</td>\n","      <td>1</td>\n","      <td>ahhh i can see the music</td>\n","      <td>biii j dbo tff uif nvtjd</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>i am the lidard uueennonenonenonenonenonenonen...</td>\n","      <td>5</td>\n","      <td>i am the lizard queen</td>\n","      <td>n fr ymj qnefwi vzjjs</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>want talk comin downnonenonenonenonenonenoneno...</td>\n","      <td>1</td>\n","      <td>cant talk comin down</td>\n","      <td>dbou ubml dpnjo epxo</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>taat you be forever dialing that phonenonenone...</td>\n","      <td>9</td>\n","      <td>must you be forever dialing that phone</td>\n","      <td>vdbc hxd kn oxanena mrjurwp cqjc yqxwn</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>oh doon hurtynonenonenonenonenonenonenonenonen...</td>\n","      <td>5</td>\n","      <td>oh cmon hurry</td>\n","      <td>tm hrts mzwwd</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>ih no its a package from ralphnonenonenonenone...</td>\n","      <td>4</td>\n","      <td>oh no its a package from ralph</td>\n","      <td>sl rs mxw e tegoeki jvsq veptl</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>irnt that just pointless busyworknonenonenonen...</td>\n","      <td>7</td>\n","      <td>isnt that just pointless busywork</td>\n","      <td>pzua aoha qbza wvpuaslzz ibzfdvyr</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>iere you go ralphnonenonenonenonenonenonenonen...</td>\n","      <td>2</td>\n","      <td>here you go ralph</td>\n","      <td>jgtg aqw iq tcnrj</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>iarow ualentinesnonenonenonenonenonenonenoneno...</td>\n","      <td>3</td>\n","      <td>happy valentines</td>\n","      <td>kdssb ydohqwlqhv</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>wtye i guessnonenonenonenonenonenonenonenoneno...</td>\n","      <td>8</td>\n","      <td>sure i guess</td>\n","      <td>aczm q ocmaa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f79baad-6edf-4844-a6cd-a97973161369')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1f79baad-6edf-4844-a6cd-a97973161369 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1f79baad-6edf-4844-a6cd-a97973161369');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9f5ad241-a1e1-4bf4-ad1c-58ed6b44138b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f5ad241-a1e1-4bf4-ad1c-58ed6b44138b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9f5ad241-a1e1-4bf4-ad1c-58ed6b44138b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_res","summary":"{\n  \"name\": \"df_res\",\n  \"rows\": 506,\n  \"fields\": [\n    {\n      \"column\": \"predicts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"ise never seen the baby get tired of it before the adultnonenonenonenonenonenonenonenonenonenonenonenonenonenone\",\n          \"whote are all wonderful things but theyve cost the church its soul and\",\n          \"isst it obvious weve degraded ourselves and set back the childrens rig\"\n        ],\n        \"num_unique_values\": 504,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"samples\": [\n          1,\n          4,\n          6\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"fine ill beat up ralph\",\n          \"thats as bad as the tasteless itchy and sambo cartoons of the late 30s the writers should be ashamed of themselves\",\n          \"come on come on lets get to the beach\"\n        ],\n        \"num_unique_values\": 500,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"rc uxxtb urtn jw jvdbnvnwc yjat\",\n          \"epou zpv tff xibu ns cvsot ibt epof up uijt divsdi\",\n          \"scxd sd ylfsyec gofo noqbknon yebcovfoc kxn cod lkmu dro mrsvnboxc bsqrdc wyfowoxd pyb nomknoc dy mywo\"\n        ],\n        \"num_unique_values\": 506,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":92}]},{"cell_type":"markdown","source":["Раскодировка происходит с разной степенью успеха.  \n","На первый взгляд от величины сдвига в кодировке результат не зависит.  \n","Как и должно быть.\n","Видимо раскодировать со случайным сдвигом не так то просто.  \n","  \n","    \n","Сохраним полученные результаты на всякий случай."],"metadata":{"id":"xXdhRTe8etj_"}},{"cell_type":"code","source":["#save_pickle(model_best, 'model_best' + '.pickle',base_dir)\n","save_pickle(df_res, 'df_res' + '.pickle',base_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mCtZJK8pICj","executionInfo":{"status":"ok","timestamp":1708086253795,"user_tz":-180,"elapsed":47,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"c575b454-0864-43b0-e286-b9bc41061ea4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["saved \"df_res.pickle\" (133.5 KiB).\n"]}]},{"cell_type":"code","source":["path_model = base_dir + 'model_best' + '.pt'\n","torch.save(model_best.state_dict(), path_model)"],"metadata":{"id":"wDdDlIfVWyuy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Генерация текста RNN моделью из реплик героев Симпсонов."],"metadata":{"id":"emj8C5or_dqs"}},{"cell_type":"markdown","source":["Построим свою RNN сеть используя только полносвязные слои.  \n","Особенностью является посимвольная обработка входных данных, без всяких векторов и оптимизаций."],"metadata":{"id":"5n5tpLXLgcwu"}},{"cell_type":"code","source":["class MyRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, result_size):\n","        super(MyRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n","        self.in2output = nn.Linear(input_size + hidden_size, output_size)\n","        self.linear = nn.Linear(output_size, result_size) # здесь result_size - это классификация на (result_size = input_size = размер словаря) символов\n","\n","    def forward(self, x, hidden_state):\n","        combined = torch.cat((x, hidden_state), 1)\n","        hidden = torch.sigmoid(self.in2hidden(combined))\n","        output = torch.sigmoid(self.in2output(combined))\n","        result = self.linear(output)\n","        return result, hidden\n","\n","    def init_hidden(self):\n","        return nn.init.kaiming_uniform_(torch.empty(1 ,self.hidden_size))\n"],"metadata":{"id":"FyZNdgsSkPzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Постараемся облегчить работу модели, выбрав для обработки только полные реплики на 50 символов и только от одного персонажа."],"metadata":{"id":"AkYVCb_Q6e6C"}},{"cell_type":"code","source":["inputs_flatt = df.loc[(df['normalized_text']. str.len () > 50) & (df[\"raw_character_text\"] == \"Lisa Simpson\")]['normalized_text'].dropna().to_list() # оставим реплики больше 10 символов\n","inputs_flatt[-5:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708086253796,"user_tz":-180,"elapsed":38,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"420734ee-8a0b-412c-8b25-604750fa6321","id":"lN26csoQA2f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i think its sad that you equate friendliness from wimpiness and i hope it will keep you from ever achieving true popularity',\n"," 'perhaps he realized how hollow the pursuit of money is and took his own life',\n"," 'too bad we didnt come dressed as popular cartoon characters',\n"," 'yeah mom guess what for a dollar a man sold me thirty-five caspers and a dozen lois lanes',\n"," 'maybe you need to play on their sympathies more lets see']"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["df.raw_character_text.unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zwe-CGoye-Oc","executionInfo":{"status":"ok","timestamp":1708086253797,"user_tz":-180,"elapsed":33,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"56049746-84de-44d2-bbfa-f6206bd73294"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Lisa Simpson', \"Lisa's Thoughts\", 'Teenage Lisa', 'Adult Lisa'],\n","      dtype=object)"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["len(inputs_flatt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8r-dOpaZnvt","executionInfo":{"status":"ok","timestamp":1708086253797,"user_tz":-180,"elapsed":27,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"f11a0b70-2af6-49db-d569-f5f678d5645f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3766"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["import statistics\n","statistics.median([len(i) for i in inputs_flatt])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kfr_XuMpbNuo","executionInfo":{"status":"ok","timestamp":1708086253798,"user_tz":-180,"elapsed":24,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"7bb4841b-b540-4996-8953-2eef26472a6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["77.0"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":[" text_flatt = [[c for c in ph] for ph in inputs_flatt if type(ph) is str]"],"metadata":{"id":"RuiMJ8HUCR3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CHARS = set('abcdefghijklmnopqrstuvwxyz ')  # все символы, которые мы хотим использовать для кодировки = наш словарь\n","INDEX_TO_CHAR = ['none'] + [w for w in CHARS]  # все неизвестные символы будут получать тег none\n","CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}  # словарь токен-индекс"],"metadata":{"id":"zEZ6NjZKdwQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(INDEX_TO_CHAR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYIE6A0u6w1o","executionInfo":{"status":"ok","timestamp":1708086253799,"user_tz":-180,"elapsed":18,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b2a40ba1-efea-4708-8307-1ad43f8d0e22"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","source":["Чтобы использовать часть кода из предыдущего обработчика,\n","определим недостающую функцию построения one_hot вектора по индексу символа."],"metadata":{"id":"dEK-k8ZG7vEY"}},{"cell_type":"code","source":["# функция построения one_hot вектора по индексу символа и перевод его в тензор торча на текущем устройстве\n","def one_hot_idx(idx):\n","  one_hot = [0 for _ in range(len(INDEX_TO_CHAR))]\n","  one_hot[idx] = 1\n","  return torch.tensor( one_hot ).unsqueeze(0).to(device).to(torch.float)\n"],"metadata":{"id":"7R5IaLQx_ARb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_idx(27)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yysqjMqg_-rs","executionInfo":{"status":"ok","timestamp":1708086254637,"user_tz":-180,"elapsed":12,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"2c78f410-c438-477d-904e-addad85ffe1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"]},"metadata":{},"execution_count":104}]},{"cell_type":"markdown","source":["Переводим символы в индексы"],"metadata":{"id":"JymGoTGQ8l9Q"}},{"cell_type":"code","source":["MAX_LEN = 50  # мы хотим ограничить максимальную длину ввода\n","X = torch.zeros((len(text_flatt), MAX_LEN), dtype=int)  # создаём пустой вектор для текста, чтобы класть в него индексы токенов\n","for i in range(len(text_flatt)):  # для каждого предложения\n","    for j, w in enumerate(inputs_flatt[i]):  # для каждого токена\n","        if j >= MAX_LEN:\n","            break\n","        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"],"metadata":{"id":"jBvm3zYxdxwH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X[0:5].shape, X[0:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjmuQaGEd7wr","executionInfo":{"status":"ok","timestamp":1708086256070,"user_tz":-180,"elapsed":43,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b385f63b-89f7-4f4a-eb6f-b2964933f36c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([5, 50]),\n"," tensor([[ 6, 18, 16, 25, 22, 15,  6, 23,  7, 16, 25, 12, 16, 25, 19,  9,  3, 10,\n","          16, 18,  9,  7,  7,  6, 19, 16, 25, 10,  9, 25, 16, 23,  9, 25,  2, 22,\n","          19, 16, 17, 12, 19,  8, 23, 25, 16, 19, 23, 17, 16,  5],\n","         [ 6, 25,  8, 16,  4,  6, 24, 19, 16,  9, 23, 16, 12, 11, 16, 12, 23,  4,\n","          15, 16,  6, 25, 16, 10,  9,  8, 16,  9, 16, 10,  2, 18,  1, 16,  9, 23,\n","          17, 16,  9, 16, 17, 19,  5,  4,  9,  1, 16, 10,  2, 18],\n","         [12, 12, 10, 16,  4, 12, 12, 24, 16, 18,  9,  7,  7,  6, 19, 16,  5, 10,\n","           9, 25, 16,  6,  8, 16, 25, 10,  9, 25, 16, 17, 12,  0, 17, 19,  3,  0,\n","           9, 10,  0, 19, 17, 22, 12, 23, 16, 17, 12, 17, 19,  3],\n","         [25, 10,  9, 25,  8, 16, 12, 24,  9, 15, 16, 21,  9, 22, 25, 16, 23, 12,\n","          21, 12, 17, 15, 16, 22, 19,  9,  4,  4, 15, 16, 21, 19,  4,  6, 19, 26,\n","          19, 17, 16,  6, 25, 16,  5, 19, 16,  5, 19, 22, 19, 16],\n","         [21,  9, 22, 25, 16, 18, 15, 16, 21,  6, 22, 25, 10, 17,  9, 15, 16,  6,\n","           8, 16,  6, 23, 16, 25,  5, 12, 16, 17,  9, 15,  8, 16,  6, 18, 16,  7,\n","          12, 23, 23,  9, 16, 21, 19, 16, 19,  6,  7, 10, 25, 16]]))"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["input_size = result_size = len(DICT_) # 28\n","hidden_size = output_size = 256\n","batch_size = 100\n","model_flatt = MyRNN(input_size, hidden_size, output_size, result_size).to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_flatt.parameters(), lr=.0001)\n","MAX_GEN_LEN = 50\n","print_interval = 10\n","#phrase = 'must you be forever dialing that phone '"],"metadata":{"id":"-1pI8n2mg4NJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_flatt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjOimUXhDvlp","executionInfo":{"status":"ok","timestamp":1708087107979,"user_tz":-180,"elapsed":332,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"9b9a3e7b-0638-4248-af30-bcc92074c4e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyRNN(\n","  (in2hidden): Linear(in_features=284, out_features=256, bias=True)\n","  (in2output): Linear(in_features=284, out_features=256, bias=True)\n","  (linear): Linear(in_features=256, out_features=28, bias=True)\n",")"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["X[5][49]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2QiVVHLHFMi","executionInfo":{"status":"ok","timestamp":1708086256072,"user_tz":-180,"elapsed":29,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"2cd2c1a8-e2f0-49dc-f9c8-ff9d391869ac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(12)"]},"metadata":{},"execution_count":109}]},{"cell_type":"markdown","source":["фспомогательная функция, чтобы убедиться, что в модель будем передовать, что надо."],"metadata":{"id":"TlXxInPD9Hbt"}},{"cell_type":"code","source":["def test1() :\n","  end_phrase = 48\n","  for j in range(int(len(X) / batch_size)):\n","          batch = X[j * batch_size:(j + 1) * batch_size]\n","          X_batch = batch[:, :-1].to(device)\n","          Y_batch = batch[:, 1:].flatten().to(device)\n","\n","          for i, (phrase, label) in enumerate(zip(X_batch, Y_batch)):\n","            #print(Y_batch, len(X_batch))\n","            for n, char in enumerate(phrase):\n","              if n == end_phrase:\n","               print(\"\\n end phrase\")\n","               break\n","              v_char = one_hot_idx(char)\n","              v_label = one_hot_idx(phrase[n+1])\n","              print(\"\\n\", i,\"\\n\",torch.max(v_char, dim=1),torch.max(v_label, dim=1))\n","              if i == 3:\n","                print(\"\\n end i\")\n","                break\n","            if j == 1:\n","               print(\"\\n end j\")\n","               break"],"metadata":{"id":"cuoR53DBOlAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test1()\n"],"metadata":{"id":"X9Qc9_zgh_9r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Курсив*"],"metadata":{"id":"XuthuhMP97MO"}},{"cell_type":"code","source":["%%time\n","# второй вариант - посимвольный\n","num_epochs = 3\n","end_phrase = 48\n","for epoch in range(num_epochs):\n","    start = time.time()\n","    train_loss = 0\n","    train_passed = 0\n","\n","    #torch.autograd.set_detect_anomaly(True)\n","\n","    model_flatt.train()\n","\n","    for j in range(int(len(X) / batch_size)):\n","        batch = X[j * batch_size:(j + 1) * batch_size]\n","        X_batch = batch[:, :-1].to(device)\n","        Y_batch = batch[:, 1:].flatten().to(device)\n","\n","        for i, (phrase, label) in enumerate(zip(X_batch, Y_batch)):\n","          hidden_state = model_flatt.init_hidden().to(device)\n","          #print(phrase, label)\n","          for n, char in enumerate(phrase):\n","            if n == end_phrase:\n","              break\n","            v_char = one_hot_idx(char)\n","            v_label = one_hot_idx(phrase[n+1])\n","            #print(v_char, v_label)\n","            result, hidden_state = model_flatt(v_char, hidden_state.detach())\n","            #print(output.shape, one_hot_idx(label).shape, one_hot_idx(label))\n","            loss = criterion(result, v_label)\n","            #print(result.shape, hidden_state.shape)\n","            train_loss += loss.item()\n","            train_passed += 1\n","\n","            optimizer.zero_grad()\n","            loss.backward(retain_graph=True)\n","            nn.utils.clip_grad_norm_(model_flatt.parameters(), 1)\n","            optimizer.step()\n","\n","        if epoch%1 == 0:\n","          print(f\"Epoch {epoch}. Step {j + 1}. Time: {time.time() - start:.3f}, Train loss: {train_loss / train_passed:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtdObO0AkHrk","outputId":"2df94190-e007-4a3f-c718-1e88060d1986","executionInfo":{"status":"ok","timestamp":1708094881430,"user_tz":-180,"elapsed":5583579,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0. Step 1. Time: 49.980, Train loss: 2.444\n","Epoch 0. Step 2. Time: 101.591, Train loss: 2.427\n","Epoch 0. Step 3. Time: 151.674, Train loss: 2.428\n","Epoch 0. Step 4. Time: 201.107, Train loss: 2.429\n","Epoch 0. Step 5. Time: 251.733, Train loss: 2.432\n","Epoch 0. Step 6. Time: 301.827, Train loss: 2.429\n","Epoch 0. Step 7. Time: 352.036, Train loss: 2.442\n","Epoch 0. Step 8. Time: 400.928, Train loss: 2.442\n","Epoch 0. Step 9. Time: 453.891, Train loss: 2.443\n","Epoch 0. Step 10. Time: 504.809, Train loss: 2.444\n","Epoch 0. Step 11. Time: 556.431, Train loss: 2.443\n","Epoch 0. Step 12. Time: 609.049, Train loss: 2.447\n","Epoch 0. Step 13. Time: 659.101, Train loss: 2.447\n","Epoch 0. Step 14. Time: 709.262, Train loss: 2.448\n","Epoch 0. Step 15. Time: 760.535, Train loss: 2.449\n","Epoch 0. Step 16. Time: 812.831, Train loss: 2.448\n","Epoch 0. Step 17. Time: 862.520, Train loss: 2.448\n","Epoch 0. Step 18. Time: 911.697, Train loss: 2.450\n","Epoch 0. Step 19. Time: 963.412, Train loss: 2.452\n","Epoch 0. Step 20. Time: 1013.555, Train loss: 2.451\n","Epoch 0. Step 21. Time: 1062.692, Train loss: 2.451\n","Epoch 0. Step 22. Time: 1112.575, Train loss: 2.452\n","Epoch 0. Step 23. Time: 1163.937, Train loss: 2.452\n","Epoch 0. Step 24. Time: 1213.578, Train loss: 2.454\n","Epoch 0. Step 25. Time: 1262.606, Train loss: 2.455\n","Epoch 0. Step 26. Time: 1314.369, Train loss: 2.455\n","Epoch 0. Step 27. Time: 1364.550, Train loss: 2.454\n","Epoch 0. Step 28. Time: 1414.134, Train loss: 2.454\n","Epoch 0. Step 29. Time: 1465.032, Train loss: 2.453\n","Epoch 0. Step 30. Time: 1517.038, Train loss: 2.453\n","Epoch 0. Step 31. Time: 1566.158, Train loss: 2.452\n","Epoch 0. Step 32. Time: 1616.443, Train loss: 2.452\n","Epoch 0. Step 33. Time: 1668.622, Train loss: 2.451\n","Epoch 0. Step 34. Time: 1717.926, Train loss: 2.450\n","Epoch 0. Step 35. Time: 1768.480, Train loss: 2.450\n","Epoch 0. Step 36. Time: 1819.467, Train loss: 2.449\n","Epoch 0. Step 37. Time: 1872.302, Train loss: 2.448\n","Epoch 1. Step 1. Time: 49.731, Train loss: 2.459\n","Epoch 1. Step 2. Time: 101.709, Train loss: 2.433\n","Epoch 1. Step 3. Time: 154.349, Train loss: 2.430\n","Epoch 1. Step 4. Time: 206.949, Train loss: 2.425\n","Epoch 1. Step 5. Time: 258.539, Train loss: 2.426\n","Epoch 1. Step 6. Time: 308.330, Train loss: 2.419\n","Epoch 1. Step 7. Time: 360.881, Train loss: 2.430\n","Epoch 1. Step 8. Time: 412.026, Train loss: 2.428\n","Epoch 1. Step 9. Time: 462.894, Train loss: 2.427\n","Epoch 1. Step 10. Time: 513.437, Train loss: 2.426\n","Epoch 1. Step 11. Time: 563.722, Train loss: 2.423\n","Epoch 1. Step 12. Time: 613.686, Train loss: 2.426\n","Epoch 1. Step 13. Time: 662.268, Train loss: 2.425\n","Epoch 1. Step 14. Time: 713.037, Train loss: 2.424\n","Epoch 1. Step 15. Time: 762.650, Train loss: 2.424\n","Epoch 1. Step 16. Time: 811.721, Train loss: 2.422\n","Epoch 1. Step 17. Time: 861.193, Train loss: 2.422\n","Epoch 1. Step 18. Time: 912.388, Train loss: 2.423\n","Epoch 1. Step 19. Time: 962.125, Train loss: 2.424\n","Epoch 1. Step 20. Time: 1011.296, Train loss: 2.422\n","Epoch 1. Step 21. Time: 1062.835, Train loss: 2.421\n","Epoch 1. Step 22. Time: 1112.823, Train loss: 2.423\n","Epoch 1. Step 23. Time: 1161.731, Train loss: 2.422\n","Epoch 1. Step 24. Time: 1211.191, Train loss: 2.423\n","Epoch 1. Step 25. Time: 1262.434, Train loss: 2.423\n","Epoch 1. Step 26. Time: 1310.845, Train loss: 2.423\n","Epoch 1. Step 27. Time: 1360.567, Train loss: 2.421\n","Epoch 1. Step 28. Time: 1410.308, Train loss: 2.421\n","Epoch 1. Step 29. Time: 1460.217, Train loss: 2.420\n","Epoch 1. Step 30. Time: 1509.731, Train loss: 2.420\n","Epoch 1. Step 31. Time: 1559.465, Train loss: 2.419\n","Epoch 1. Step 32. Time: 1609.348, Train loss: 2.419\n","Epoch 1. Step 33. Time: 1659.539, Train loss: 2.417\n","Epoch 1. Step 34. Time: 1709.494, Train loss: 2.416\n","Epoch 1. Step 35. Time: 1758.365, Train loss: 2.416\n","Epoch 1. Step 36. Time: 1808.853, Train loss: 2.414\n","Epoch 1. Step 37. Time: 1859.377, Train loss: 2.413\n","Epoch 2. Step 1. Time: 50.426, Train loss: 2.416\n","Epoch 2. Step 2. Time: 100.252, Train loss: 2.391\n","Epoch 2. Step 3. Time: 151.534, Train loss: 2.387\n","Epoch 2. Step 4. Time: 201.276, Train loss: 2.381\n","Epoch 2. Step 5. Time: 249.474, Train loss: 2.383\n","Epoch 2. Step 6. Time: 300.396, Train loss: 2.377\n","Epoch 2. Step 7. Time: 350.231, Train loss: 2.389\n","Epoch 2. Step 8. Time: 398.713, Train loss: 2.387\n","Epoch 2. Step 9. Time: 447.931, Train loss: 2.386\n","Epoch 2. Step 10. Time: 498.565, Train loss: 2.386\n","Epoch 2. Step 11. Time: 546.517, Train loss: 2.382\n","Epoch 2. Step 12. Time: 595.883, Train loss: 2.386\n","Epoch 2. Step 13. Time: 645.616, Train loss: 2.386\n","Epoch 2. Step 14. Time: 693.922, Train loss: 2.385\n","Epoch 2. Step 15. Time: 743.233, Train loss: 2.386\n","Epoch 2. Step 16. Time: 793.206, Train loss: 2.384\n","Epoch 2. Step 17. Time: 842.909, Train loss: 2.384\n","Epoch 2. Step 18. Time: 896.618, Train loss: 2.386\n","Epoch 2. Step 19. Time: 948.953, Train loss: 2.387\n","Epoch 2. Step 20. Time: 1000.726, Train loss: 2.385\n","Epoch 2. Step 21. Time: 1051.869, Train loss: 2.384\n","Epoch 2. Step 22. Time: 1101.941, Train loss: 2.387\n","Epoch 2. Step 23. Time: 1152.155, Train loss: 2.386\n","Epoch 2. Step 24. Time: 1202.955, Train loss: 2.388\n","Epoch 2. Step 25. Time: 1253.457, Train loss: 2.388\n","Epoch 2. Step 26. Time: 1301.899, Train loss: 2.388\n","Epoch 2. Step 27. Time: 1351.774, Train loss: 2.387\n","Epoch 2. Step 28. Time: 1402.187, Train loss: 2.387\n","Epoch 2. Step 29. Time: 1452.328, Train loss: 2.387\n","Epoch 2. Step 30. Time: 1503.076, Train loss: 2.387\n","Epoch 2. Step 31. Time: 1552.562, Train loss: 2.386\n","Epoch 2. Step 32. Time: 1601.598, Train loss: 2.386\n","Epoch 2. Step 33. Time: 1650.056, Train loss: 2.386\n","Epoch 2. Step 34. Time: 1699.857, Train loss: 2.385\n","Epoch 2. Step 35. Time: 1751.805, Train loss: 2.385\n","Epoch 2. Step 36. Time: 1800.799, Train loss: 2.383\n","Epoch 2. Step 37. Time: 1851.472, Train loss: 2.383\n","CPU times: user 1h 24min 45s, sys: 7min 15s, total: 1h 32min\n","Wall time: 1h 33min 3s\n"]}]},{"cell_type":"code","source":["path_model = base_dir + 'model_flatt' + '.pt'\n","torch.save(model_flatt.state_dict(), path_model)"],"metadata":{"id":"qGTWwPCYNsp2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Посчитаем точность."],"metadata":{"id":"ipAONH4I9Z_w"}},{"cell_type":"code","source":["%%time\n","num_correct = 0\n","num_samples = 0\n","num_samples = len(X)\n","end_phrase = 48\n","\n","model_flatt.eval()\n","\n","with torch.no_grad():\n","  for j in range(int(len(X) / batch_size)):\n","        batch = X[j * batch_size:(j + 1) * batch_size]\n","        X_batch = batch[:, :-1].to(device)\n","        Y_batch = batch[:, 1:].flatten().to(device)\n","\n","        for i, (phrase, label) in enumerate(zip(X_batch, Y_batch)):\n","          hidden_state = model_flatt.init_hidden().to(device)\n","          #print(phrase, label)\n","          for n, char in enumerate(phrase):\n","            if n == end_phrase:\n","              break\n","            v_char = one_hot_idx(char)\n","            v_label = one_hot_idx(phrase[n+1])\n","            n_label = phrase[n+1]\n","            #print(v_char, v_label)\n","            result, hidden_state = model_flatt(v_char, hidden_state)\n","\n","            _, pred = torch.max(result, dim=1)\n","            num_correct += bool(pred == n_label)\n","            num_samples += 1\n","\n","print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")\n"],"metadata":{"id":"inMd4Ceg0wVl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708094928551,"user_tz":-180,"elapsed":47127,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"cb16f162-2e59-4147-bf15-3f41d3d19a26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 30.1335%\n","CPU times: user 46.6 s, sys: 132 ms, total: 46.7 s\n","Wall time: 47.2 s\n"]}]},{"cell_type":"code","source":["#MAX_GEN_LEN = 49\n","phrase = 'must you be forever dialing that phone '\n","MAX_GEN_LEN = len(phrase) -2\n","MAX_GEN_LEN"],"metadata":{"id":"_PjXIhWrgm3s","executionInfo":{"status":"ok","timestamp":1708094928551,"user_tz":-180,"elapsed":43,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19d26951-0532-43df-e125-0368a5f114ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{},"execution_count":142}]},{"cell_type":"markdown","source":["создадим функцию для генерации последовательностей из модели."],"metadata":{"id":"XRBSd0pAg5Fj"}},{"cell_type":"code","metadata":{"id":"G0WvpMJKASqc"},"source":["def generate_sentence(txt_list):\n","\n","    sentence =  [c for c in txt_list]\n","    x = torch.zeros((1, len(sentence)), dtype=int).to(device)\n","\n","    model_flatt.eval()\n","\n","    for j,w in enumerate(sentence):\n","        if j >= MAX_GEN_LEN:\n","            break\n","        x[0, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])\n","    hidden_state = model_flatt.init_hidden().to(device)\n","    for i in range(MAX_GEN_LEN):\n","        v_char = one_hot_idx(x[0, i])\n","        #print(v_char)\n","        pred, hidden_state  = model_flatt(v_char,hidden_state)\n","        #w = torch.argmax(pred[-1, -1, :], keepdim=True)\n","        w = torch.argmax(pred[-1, :], keepdim=True)\n","        #_, pred = torch.max(result, dim=1)\n","        #print(pred, w)\n","        #x = torch.cat([x, w.unsqueeze(0).unsqueeze(1)], axis=1)\n","        ww = INDEX_TO_CHAR[w.item()]\n","        if ww == 'none':\n","            break\n","\n","        sentence.append(ww)\n","\n","    return ''.join(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_sentence(phrase)"],"metadata":{"id":"rufyY9uAMe3P","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1708094928984,"user_tz":-180,"elapsed":469,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b5101b43-f37a-496a-9032-5297a7a12c50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'must you be forever dialing that phone os  touste toue e et nnlng then teeu '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":144}]},{"cell_type":"markdown","source":["сгенерировалось так себе."],"metadata":{"id":"lKXblk4O5SLL"}},{"cell_type":"markdown","source":["Модель рекурентной ячейки из полносвязных слоев для посимвольной обработки - создал.  \n","Считается без ошибок, но очень медленно и особой сходимости не наблюдается.  \n","Видимо в стандартном классе из библиотеки архитектура намного лучше и оптимизация присутствует.  \n","\n","До хорошего результата улучшать и улучшать :):\n","\n"],"metadata":{"id":"7LRIsnkT9hsb"}},{"cell_type":"markdown","source":["<font color=red>Попробуем улучшить обучаемость модели строя батчи не построчно пофразово, а склеив фразы в один текст и выбирая оттуда батчи со сдвигом."],"metadata":{"id":"ETkg2ZbzlmNy"}},{"cell_type":"code","source":["inline_text_flatt = ' '.join(inputs_flatt)\n","len(inline_text_flatt), inline_text_flatt[0:1000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4p2nS5cnNca","executionInfo":{"status":"ok","timestamp":1708173150325,"user_tz":-180,"elapsed":23,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b26e0f0d-97c5-4b7f-d41d-cb0d8f0b706c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(332920,\n"," 'im trying to teach maggie that nature doesnt end with the barnyard i want her to have all the advantages that i didnt have its like an ox only it has a hump and a dewlap hump and dew-lap hump and dew-lap ooh look maggie what is that do-dec-ah-edron dodecahedron thats okay bart nobody really believed it we were just trying to scare you bart my birthday is in two days im gonna be eight years old its a big number -- almost double digits bart will you please let me pour my little heart out bart i do so much for you and yet you have disappointed me on every one of my birthdays ive made things for you but youve lost or broken them in hours but okay well forget all well all right -- if you listen to the poem i just wrote meditations on turning eight by lisa simpson i had a cat named snowball -- she died she died mom said she was sleeping -- she lied she lied why oh why is my cat dead couldnt that chrysler hit me instead i had a hamster named snuffy -- he died -- bart in the split second befor')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["inline_text_flatt = re.sub('[^a-z ]', ' ', inline_text_flatt)\n","inline_text_flatt = re.sub('\\s+', ' ', inline_text_flatt) # дополнительно фильтруются множественные пробелы\n","len(inline_text_flatt), inline_text_flatt[0:1000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnilTmdLn-Fn","executionInfo":{"status":"ok","timestamp":1708173150326,"user_tz":-180,"elapsed":20,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"ee4f5430-7308-4137-83b4-f603240e0a6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(331962,\n"," 'im trying to teach maggie that nature doesnt end with the barnyard i want her to have all the advantages that i didnt have its like an ox only it has a hump and a dewlap hump and dew lap hump and dew lap ooh look maggie what is that do dec ah edron dodecahedron thats okay bart nobody really believed it we were just trying to scare you bart my birthday is in two days im gonna be eight years old its a big number almost double digits bart will you please let me pour my little heart out bart i do so much for you and yet you have disappointed me on every one of my birthdays ive made things for you but youve lost or broken them in hours but okay well forget all well all right if you listen to the poem i just wrote meditations on turning eight by lisa simpson i had a cat named snowball she died she died mom said she was sleeping she lied she lied why oh why is my cat dead couldnt that chrysler hit me instead i had a hamster named snuffy he died bart in the split second before he died i bet sc')"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["INDEX_TO_CHAR = sorted(list(set(inline_text_flatt)))\n","CHAR_TO_INDEX = {c: i for i, c in enumerate(INDEX_TO_CHAR)}"],"metadata":{"id":"6yh9x4OWn-gz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Нарежем текс по фразам со сдвигом."],"metadata":{"id":"w-sMuLDYIvAX"}},{"cell_type":"code","source":["MAX_LEN = 40 # длиннее плохо запомнится и будет хуже обучаться\n","STEP = 3 # нарезаем по 40 с шагом 3: 0-40, 2-42, 5-45 и т.д.\n","SENTENCES = []\n","NEXT_CHARS = []\n","for i in range(0, len(inline_text_flatt) - MAX_LEN, STEP):\n","    SENTENCES.append(inline_text_flatt[i: i + MAX_LEN])\n","    NEXT_CHARS.append(inline_text_flatt[i + MAX_LEN])\n","print('Num sents:', len(SENTENCES))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFU_22qzn-jD","executionInfo":{"status":"ok","timestamp":1708174008531,"user_tz":-180,"elapsed":378,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"7d40c312-9202-42d7-b73e-43facac15e77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num sents: 110641\n"]}]},{"cell_type":"markdown","source":["Ограничим обучающую выборку для скорости."],"metadata":{"id":"tZ-yfUjVI4st"}},{"cell_type":"code","source":["MAX_SENTENCES = 20000 # Ограничим кол-во фраз в базе обучения из-за низкой производительности\n","# MAX_SENTENCES = 5000"],"metadata":{"id":"A7I53EyuAHPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(SENTENCES[0:MAX_SENTENCES])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTQss8_zBJw-","executionInfo":{"status":"ok","timestamp":1708175608855,"user_tz":-180,"elapsed":6,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"23426769-9efc-4417-d3c3-0a971fc32da8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20000"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","source":["Векторизуем (кодируем) символы."],"metadata":{"id":"p06AuqQaJDCI"}},{"cell_type":"code","metadata":{"id":"EHPHQII_6MUV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"73c0d0c3-c9e9-4f87-c8f6-04549229933d","executionInfo":{"status":"ok","timestamp":1708175614614,"user_tz":-180,"elapsed":5762,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}}},"source":["print('Vectorization...')\n","X = torch.zeros((MAX_SENTENCES, MAX_LEN), dtype=int)\n","Y = torch.zeros((MAX_SENTENCES), dtype=int)\n","for i, sentence in enumerate(SENTENCES[0:MAX_SENTENCES]):\n","    for t, char in enumerate(sentence):\n","        X[i, t] = CHAR_TO_INDEX[char]\n","    Y[i] = CHAR_TO_INDEX[NEXT_CHARS[i]]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectorization...\n"]}]},{"cell_type":"code","metadata":{"id":"n7MP7Jzi7PAN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d405ef28-1613-429f-d97c-cbd107df76d3","executionInfo":{"status":"ok","timestamp":1708175614615,"user_tz":-180,"elapsed":40,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}}},"source":["X[0:1], len(X[0:1][0]), Y[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 9, 13,  0, 20, 18, 25,  9, 14,  7,  0, 20, 15,  0, 20,  5,  1,  3,  8,\n","           0, 13,  1,  7,  7,  9,  5,  0, 20,  8,  1, 20,  0, 14,  1, 20, 21, 18,\n","           5,  0,  4, 15]]),\n"," 40,\n"," tensor(5))"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"4XKb2CyB6nwL"},"source":["BATCH_SIZE=512\n","dataset = torch.utils.data.TensorDataset(X, Y)\n","data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True) # shuffle=True перемешивать данные\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(INDEX_TO_CHAR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708175614617,"user_tz":-180,"elapsed":33,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"361405a2-9155-479f-f311-376caa5328b9","id":"o_avbbY9c3TN"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27"]},"metadata":{},"execution_count":90}]},{"cell_type":"markdown","source":["Чтобы использовать часть кода из предыдущего обработчика,\n","определим недостающую функцию построения one_hot вектора по индексу символа."],"metadata":{"id":"v0QUEw01c3TO"}},{"cell_type":"code","source":["# функция построения one_hot вектора по индексу символа и перевод его в тензор торча на текущем устройстве\n","def one_hot_idx(idx):\n","  one_hot = [0 for _ in range(len(INDEX_TO_CHAR))]\n","  one_hot[idx] = 1\n","  return torch.tensor( one_hot ).unsqueeze(0).to(device).to(torch.float)\n"],"metadata":{"id":"uijRxg02c3TO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_idx(26)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708175614618,"user_tz":-180,"elapsed":29,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"506cb717-dcfc-4356-b717-a170c7b55b19","id":"j_wqk3Spc3TP"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 1.]])"]},"metadata":{},"execution_count":92}]},{"cell_type":"markdown","source":["Обучим модель."],"metadata":{"id":"N9aTrlpeJQdr"}},{"cell_type":"code","source":["input_size = result_size = len(INDEX_TO_CHAR) # 27\n","hidden_size = output_size = 256\n","batch_size = 500\n","model_flatt = MyRNN(input_size, hidden_size, output_size, result_size).to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_flatt.parameters(), lr=.0001)\n","MAX_GEN_LEN = 40\n","print_interval = 10\n","#phrase = 'must you be forever dialing that phone '"],"metadata":{"id":"U54uUOPgc3TQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_flatt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708175614619,"user_tz":-180,"elapsed":24,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"d541385e-9f9a-48b6-fb7f-54037a7cf4e0","id":"z8ylfya8c3TR"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyRNN(\n","  (in2hidden): Linear(in_features=283, out_features=256, bias=True)\n","  (in2output): Linear(in_features=283, out_features=256, bias=True)\n","  (linear): Linear(in_features=256, out_features=27, bias=True)\n",")"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["X[5][39],len(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708175614620,"user_tz":-180,"elapsed":21,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"f9f2069b-0b5b-498e-f5cd-9a5601245115","id":"L_ZD_IH4c3TR"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(20), 20000)"]},"metadata":{},"execution_count":95}]},{"cell_type":"markdown","source":["вспомогательная функция, чтобы убедиться, что в модель будем передовать, что надо."],"metadata":{"id":"DAdWQytCc3TS"}},{"cell_type":"code","source":["def test1() :\n","  end_phrase = 39\n","  for j in range(int(len(X) / batch_size)):\n","          batch = X[j * batch_size:(j + 1) * batch_size]\n","          X_batch = batch.to(device)\n","\n","\n","          for i, phrase in enumerate(X_batch):\n","            print(\"\\n batch\",i,len(X_batch), \"\\n\")\n","            for n, char in enumerate(phrase):\n","              if n == end_phrase:\n","               print(\"\\n end phrase\")\n","               break\n","              v_char = one_hot_idx(char)\n","              v_label = one_hot_idx(phrase[n+1])\n","              print(\"\\n\", i,\"\\n\",torch.max(v_char, dim=1),torch.max(v_label, dim=1))\n","              if i == 3:\n","                print(\"\\n end i\")\n","                break\n","            if j == 1:\n","               print(\"\\n end j\")\n","               break"],"metadata":{"id":"0yaiIId5c3TS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test1()\n"],"metadata":{"id":"OKIMBX1Qc3TT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# второй вариант - посимвольный\n","num_epochs = 3\n","end_phrase = 39\n","for epoch in range(num_epochs):\n","    start = time.time()\n","    train_loss = 0\n","    train_passed = 0\n","\n","    #torch.autograd.set_detect_anomaly(True)\n","\n","    model_flatt.train()\n","\n","    for j in range(int(len(X) / batch_size)):\n","        batch = X[j * batch_size:(j + 1) * batch_size]\n","        X_batch = batch.to(device)\n","\n","        for i, phrase in enumerate(X_batch):\n","          hidden_state = model_flatt.init_hidden().to(device)\n","          #print(phrase, label)\n","          for n, char in enumerate(phrase):\n","            if n == end_phrase:\n","              break\n","            v_char = one_hot_idx(char)\n","            v_label = one_hot_idx(phrase[n+1])\n","            #print(v_char, v_label)\n","            result, hidden_state = model_flatt(v_char, hidden_state.detach())\n","            #print(output.shape, one_hot_idx(label).shape, one_hot_idx(label))\n","            loss = criterion(result, v_label)\n","            train_loss += loss.item()\n","            train_passed += 1\n","\n","            optimizer.zero_grad()\n","            loss.backward(retain_graph=True)\n","            nn.utils.clip_grad_norm_(model_flatt.parameters(), 1)\n","            optimizer.step()\n","\n","        if epoch%1 == 0:\n","          print(f\"Epoch {epoch}. Step {j + 1}. Time: {time.time() - start:.3f}, Train loss: {train_loss / train_passed:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"48163c95-45ca-44d7-bb08-0185741313b3","executionInfo":{"status":"ok","timestamp":1708180829215,"user_tz":-180,"elapsed":5214609,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"id":"WEW_efBVc3TU"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0. Step 1. Time: 45.288, Train loss: 2.496\n","Epoch 0. Step 2. Time: 89.253, Train loss: 2.433\n","Epoch 0. Step 3. Time: 132.685, Train loss: 2.400\n","Epoch 0. Step 4. Time: 175.329, Train loss: 2.403\n","Epoch 0. Step 5. Time: 219.976, Train loss: 2.403\n","Epoch 0. Step 6. Time: 263.418, Train loss: 2.390\n","Epoch 0. Step 7. Time: 305.901, Train loss: 2.385\n","Epoch 0. Step 8. Time: 350.011, Train loss: 2.381\n","Epoch 0. Step 9. Time: 392.051, Train loss: 2.381\n","Epoch 0. Step 10. Time: 435.064, Train loss: 2.372\n","Epoch 0. Step 11. Time: 480.543, Train loss: 2.363\n","Epoch 0. Step 12. Time: 523.460, Train loss: 2.363\n","Epoch 0. Step 13. Time: 566.922, Train loss: 2.361\n","Epoch 0. Step 14. Time: 609.312, Train loss: 2.359\n","Epoch 0. Step 15. Time: 652.603, Train loss: 2.352\n","Epoch 0. Step 16. Time: 694.884, Train loss: 2.351\n","Epoch 0. Step 17. Time: 737.268, Train loss: 2.349\n","Epoch 0. Step 18. Time: 781.620, Train loss: 2.344\n","Epoch 0. Step 19. Time: 825.219, Train loss: 2.343\n","Epoch 0. Step 20. Time: 867.727, Train loss: 2.337\n","Epoch 0. Step 21. Time: 911.358, Train loss: 2.338\n","Epoch 0. Step 22. Time: 954.075, Train loss: 2.336\n","Epoch 0. Step 23. Time: 997.531, Train loss: 2.334\n","Epoch 0. Step 24. Time: 1041.832, Train loss: 2.332\n","Epoch 0. Step 25. Time: 1085.516, Train loss: 2.330\n","Epoch 0. Step 26. Time: 1128.436, Train loss: 2.328\n","Epoch 0. Step 27. Time: 1173.375, Train loss: 2.328\n","Epoch 0. Step 28. Time: 1216.240, Train loss: 2.323\n","Epoch 0. Step 29. Time: 1259.149, Train loss: 2.325\n","Epoch 0. Step 30. Time: 1303.208, Train loss: 2.326\n","Epoch 0. Step 31. Time: 1345.795, Train loss: 2.327\n","Epoch 0. Step 32. Time: 1389.904, Train loss: 2.327\n","Epoch 0. Step 33. Time: 1434.981, Train loss: 2.325\n","Epoch 0. Step 34. Time: 1478.263, Train loss: 2.326\n","Epoch 0. Step 35. Time: 1521.508, Train loss: 2.324\n","Epoch 0. Step 36. Time: 1564.762, Train loss: 2.323\n","Epoch 0. Step 37. Time: 1609.599, Train loss: 2.324\n","Epoch 0. Step 38. Time: 1654.448, Train loss: 2.325\n","Epoch 0. Step 39. Time: 1698.103, Train loss: 2.324\n","Epoch 0. Step 40. Time: 1742.294, Train loss: 2.324\n","Epoch 1. Step 1. Time: 43.196, Train loss: 2.291\n","Epoch 1. Step 2. Time: 86.772, Train loss: 2.309\n","Epoch 1. Step 3. Time: 132.035, Train loss: 2.300\n","Epoch 1. Step 4. Time: 175.020, Train loss: 2.318\n","Epoch 1. Step 5. Time: 217.672, Train loss: 2.324\n","Epoch 1. Step 6. Time: 261.887, Train loss: 2.318\n","Epoch 1. Step 7. Time: 305.448, Train loss: 2.316\n","Epoch 1. Step 8. Time: 348.043, Train loss: 2.318\n","Epoch 1. Step 9. Time: 391.729, Train loss: 2.326\n","Epoch 1. Step 10. Time: 434.925, Train loss: 2.321\n","Epoch 1. Step 11. Time: 478.527, Train loss: 2.317\n","Epoch 1. Step 12. Time: 522.344, Train loss: 2.319\n","Epoch 1. Step 13. Time: 566.957, Train loss: 2.319\n","Epoch 1. Step 14. Time: 609.560, Train loss: 2.323\n","Epoch 1. Step 15. Time: 652.544, Train loss: 2.319\n","Epoch 1. Step 16. Time: 696.588, Train loss: 2.319\n","Epoch 1. Step 17. Time: 739.816, Train loss: 2.318\n","Epoch 1. Step 18. Time: 782.222, Train loss: 2.315\n","Epoch 1. Step 19. Time: 825.936, Train loss: 2.316\n","Epoch 1. Step 20. Time: 868.322, Train loss: 2.313\n","Epoch 1. Step 21. Time: 911.113, Train loss: 2.315\n","Epoch 1. Step 22. Time: 955.152, Train loss: 2.315\n","Epoch 1. Step 23. Time: 998.994, Train loss: 2.314\n","Epoch 1. Step 24. Time: 1042.323, Train loss: 2.314\n","Epoch 1. Step 25. Time: 1086.417, Train loss: 2.312\n","Epoch 1. Step 26. Time: 1129.436, Train loss: 2.310\n","Epoch 1. Step 27. Time: 1171.848, Train loss: 2.311\n","Epoch 1. Step 28. Time: 1214.645, Train loss: 2.307\n","Epoch 1. Step 29. Time: 1258.816, Train loss: 2.310\n","Epoch 1. Step 30. Time: 1301.395, Train loss: 2.312\n","Epoch 1. Step 31. Time: 1343.620, Train loss: 2.314\n","Epoch 1. Step 32. Time: 1387.293, Train loss: 2.313\n","Epoch 1. Step 33. Time: 1430.739, Train loss: 2.312\n","Epoch 1. Step 34. Time: 1474.886, Train loss: 2.314\n","Epoch 1. Step 35. Time: 1519.129, Train loss: 2.312\n","Epoch 1. Step 36. Time: 1562.239, Train loss: 2.312\n","Epoch 1. Step 37. Time: 1604.609, Train loss: 2.313\n","Epoch 1. Step 38. Time: 1647.755, Train loss: 2.314\n","Epoch 1. Step 39. Time: 1694.042, Train loss: 2.313\n","Epoch 1. Step 40. Time: 1737.681, Train loss: 2.313\n","Epoch 2. Step 1. Time: 43.947, Train loss: 2.289\n","Epoch 2. Step 2. Time: 89.136, Train loss: 2.308\n","Epoch 2. Step 3. Time: 132.420, Train loss: 2.298\n","Epoch 2. Step 4. Time: 176.500, Train loss: 2.318\n","Epoch 2. Step 5. Time: 221.025, Train loss: 2.325\n","Epoch 2. Step 6. Time: 263.919, Train loss: 2.320\n","Epoch 2. Step 7. Time: 306.536, Train loss: 2.318\n","Epoch 2. Step 8. Time: 350.286, Train loss: 2.320\n","Epoch 2. Step 9. Time: 392.801, Train loss: 2.329\n","Epoch 2. Step 10. Time: 435.587, Train loss: 2.324\n","Epoch 2. Step 11. Time: 478.203, Train loss: 2.320\n","Epoch 2. Step 12. Time: 521.857, Train loss: 2.322\n","Epoch 2. Step 13. Time: 564.806, Train loss: 2.321\n","Epoch 2. Step 14. Time: 606.751, Train loss: 2.326\n","Epoch 2. Step 15. Time: 649.394, Train loss: 2.322\n","Epoch 2. Step 16. Time: 690.846, Train loss: 2.322\n","Epoch 2. Step 17. Time: 732.339, Train loss: 2.322\n","Epoch 2. Step 18. Time: 773.890, Train loss: 2.318\n","Epoch 2. Step 19. Time: 818.416, Train loss: 2.319\n","Epoch 2. Step 20. Time: 862.424, Train loss: 2.316\n","Epoch 2. Step 21. Time: 904.525, Train loss: 2.318\n","Epoch 2. Step 22. Time: 947.797, Train loss: 2.318\n","Epoch 2. Step 23. Time: 990.481, Train loss: 2.318\n","Epoch 2. Step 24. Time: 1033.806, Train loss: 2.317\n","Epoch 2. Step 25. Time: 1077.346, Train loss: 2.316\n","Epoch 2. Step 26. Time: 1121.885, Train loss: 2.314\n","Epoch 2. Step 27. Time: 1163.859, Train loss: 2.314\n","Epoch 2. Step 28. Time: 1205.926, Train loss: 2.311\n","Epoch 2. Step 29. Time: 1248.967, Train loss: 2.314\n","Epoch 2. Step 30. Time: 1290.902, Train loss: 2.316\n","Epoch 2. Step 31. Time: 1334.052, Train loss: 2.318\n","Epoch 2. Step 32. Time: 1379.699, Train loss: 2.318\n","Epoch 2. Step 33. Time: 1423.186, Train loss: 2.317\n","Epoch 2. Step 34. Time: 1466.628, Train loss: 2.318\n","Epoch 2. Step 35. Time: 1510.349, Train loss: 2.317\n","Epoch 2. Step 36. Time: 1556.010, Train loss: 2.316\n","Epoch 2. Step 37. Time: 1599.432, Train loss: 2.317\n","Epoch 2. Step 38. Time: 1643.513, Train loss: 2.319\n","Epoch 2. Step 39. Time: 1689.507, Train loss: 2.318\n","Epoch 2. Step 40. Time: 1734.072, Train loss: 2.318\n","CPU times: user 1h 24min 59s, sys: 54.1 s, total: 1h 25min 53s\n","Wall time: 1h 26min 54s\n"]}]},{"cell_type":"code","source":["path_model = base_dir + 'model_flatt' + '.pt'\n","torch.save(model_flatt.state_dict(), path_model)"],"metadata":{"id":"wM-XNWjec3TV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Посчитаем точность."],"metadata":{"id":"UU6D-1j6c3TV"}},{"cell_type":"code","source":["%%time\n","num_correct = 0\n","num_samples = 0\n","num_samples = len(X)\n","end_phrase = 39\n","\n","model_flatt.eval()\n","\n","with torch.no_grad():\n","  for j in range(int(len(X) / batch_size)):\n","        batch = X[j * batch_size:(j + 1) * batch_size]\n","        X_batch = batch.to(device)\n","\n","        for i, phrase in enumerate(X_batch):\n","\n","          hidden_state = model_flatt.init_hidden().to(device)\n","          #print(phrase, label)\n","          for n, char in enumerate(phrase):\n","            if n == end_phrase:\n","              break\n","            v_char = one_hot_idx(char)\n","            v_label = one_hot_idx(phrase[n+1])\n","            n_label = phrase[n+1]\n","            #print(v_char, v_label)\n","            result, hidden_state = model_flatt(v_char, hidden_state)\n","\n","            _, pred = torch.max(result, dim=1)\n","            num_correct += bool(pred == n_label)\n","            num_samples += 1\n","\n","print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708181025344,"user_tz":-180,"elapsed":196136,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"1aaf46b4-b138-4a17-b4d2-896ce3b07ce3","id":"udTwFqC-c3TW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 27.9464%\n","CPU times: user 3min 14s, sys: 447 ms, total: 3min 14s\n","Wall time: 3min 16s\n"]}]},{"cell_type":"markdown","source":["5000 -  Accuracy: 27.7025%  \n","20000 - Accuracy: 27.9464%\n","\n","Базу обучения увеличил в 4 раза, а Accuracy возросло только на 0,25%.\n","\n"],"metadata":{"id":"oAQUdXQUMdss"}},{"cell_type":"code","source":["#MAX_GEN_LEN = 49\n","phrase = 'must you be forever dialing that phone '\n","MAX_GEN_LEN = len(phrase) -2\n","MAX_GEN_LEN"],"metadata":{"executionInfo":{"status":"ok","timestamp":1708181025345,"user_tz":-180,"elapsed":58,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea95ecd4-f078-476c-f09d-001f204f3317","id":"ajyzGWjtc3TX"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","source":["создадим функцию для генерации последовательностей из модели."],"metadata":{"id":"Uh3hC4oMc3TY"}},{"cell_type":"code","metadata":{"id":"6KH5-qUmc3TY"},"source":["def generate_sentence(txt_list):\n","\n","    sentence =  [c for c in txt_list]\n","    x = torch.zeros((1, len(sentence)), dtype=int).to(device)\n","\n","    model_flatt.eval()\n","\n","    for j,w in enumerate(sentence):\n","        if j >= MAX_GEN_LEN:\n","            break\n","        x[0, j] = CHAR_TO_INDEX.get(w, 0)\n","    hidden_state = model_flatt.init_hidden().to(device)\n","    for i in range(MAX_GEN_LEN):\n","        v_char = one_hot_idx(x[0, i])\n","        #print(v_char)\n","        pred, hidden_state  = model_flatt(v_char,hidden_state)\n","        w = torch.argmax(pred[-1, :], keepdim=True)\n","        ww = INDEX_TO_CHAR[w.item()]\n","\n","        sentence.append(ww)\n","\n","    return ''.join(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_sentence(phrase)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1708181025346,"user_tz":-180,"elapsed":52,"user":{"displayName":"Andrey Murashka","userId":"14946180106951455302"}},"outputId":"b758bea5-fb6e-4b18-d4db-514f012c03f2","id":"SjGDfZHvc3TZ"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'must you be forever dialing that phone  t  ioutse s n  e esonn tt ihet iient'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","source":["И с генерацией лучше не стало. Второй способ отбора обучающей выборки улучшения не принес.\n","Самописный слой RNN работает заметно хуже библиотечного.\n"],"metadata":{"id":"iV_bcGcrc3TZ"}}]}